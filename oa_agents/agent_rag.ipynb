{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50a37d99",
   "metadata": {},
   "source": [
    "### Importing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54d150c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import minsearch \n",
    "\n",
    "import json\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "from minsearch import AppendableIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89419eaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load environment variables\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a647e449",
   "metadata": {},
   "source": [
    "### Loading documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ad593b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../documents.json', 'rt') as f_in: \n",
    "    docs_raw = json.load(f_in)\n",
    "\n",
    "\n",
    "documents = [] \n",
    "\n",
    "# looping on all courses\n",
    "for course_dict in docs_raw:\n",
    "    # looping on all documents for each course \n",
    "    for doc in course_dict['documents']:\n",
    "        doc['course'] = course_dict['course']\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf9494ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"Yes, even if you don't register, you're still eligible to submit the homeworks.\\nBe aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\",\n",
       " 'section': 'General course-related questions',\n",
       " 'question': 'Course - Can I still join the course after the start date?',\n",
       " 'course': 'data-engineering-zoomcamp'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[2] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589cf827",
   "metadata": {},
   "source": [
    "### Indexing the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4343bf38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.append.AppendableIndex at 0x23382273220>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = AppendableIndex(\n",
    "    text_fields = [\"question\", \"text\", \"section\"], # search fields\n",
    "    keyword_fields = [\"course\"] # filtering field\n",
    ")\n",
    "\n",
    "index.fit(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff5da958",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'Yes, you can. You won’t be able to submit some of the homeworks, but you can still take part in the course.\\nIn order to get a certificate, you need to submit 2 out of 3 course projects and review 3 peers’ Projects by the deadline. It means that if you join the course at the end of November and manage to work on two projects, you will still be eligible for a certificate.',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'The course has already started. Can I still join it?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " {'text': \"Yes, even if you don't register, you're still eligible to submit the homeworks.\\nBe aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\",\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - Can I still join the course after the start date?',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': \"Here’s how you join a in Slack: https://slack.com/help/articles/205239967-Join-a-channel\\nClick “All channels” at the top of your left sidebar. If you don't see this option, click “More” to find it.\\nBrowse the list of public channels in your workspace, or use the search bar to search by channel name or description.\\nSelect a channel from the list to view it.\\nClick Join Channel.\\nDo we need to provide the GitHub link to only our code corresponding to the homework questions?\\nYes. You are required to provide the URL to your repo in order to receive a grade\",\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'I’m new to Slack and can’t find the course channel. Where is it?',\n",
       "  'course': 'machine-learning-zoomcamp'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.search(\"can I still join the course ?\", num_results=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "848c01db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query):\n",
    "    boost = {'question': 3.0, 'section': 0.5}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={'course': 'data-engineering-zoomcamp'},\n",
    "        boost_dict=boost,\n",
    "        num_results = 5,\n",
    "        output_ids=True\n",
    "    )\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f66d3574",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': \"Yes, even if you don't register, you're still eligible to submit the homeworks.\\nBe aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\",\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - Can I still join the course after the start date?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  '_id': 2},\n",
       " {'text': \"No, you can only get a certificate if you finish the course with a “live” cohort. We don't award certificates for the self-paced mode. The reason is you need to peer-review capstone(s) after submitting a project. You can only peer-review projects at the time the course is running.\",\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Certificate - Can I follow the course in a self-paced mode and get a certificate?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  '_id': 11},\n",
       " {'text': 'Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\\nYou can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - Can I follow the course after it finishes?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  '_id': 7},\n",
       " {'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\",\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - When will the course start?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  '_id': 0},\n",
       " {'text': \"You don't need it. You're accepted. You can also just start learning and submitting homework without registering. It is not checked against any registered list. Registration is just to gauge interest before the start date.\",\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - I have registered for the Data Engineering Bootcamp. When can I expect to receive the confirmation email?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  '_id': 3}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = 'Can I still join in the course ?'\n",
    "\n",
    "search(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fafa67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "<QUESTION>\n",
    "{question}\n",
    "</QUESTION>\n",
    "\n",
    "<CONTEXT>\n",
    "{context}\n",
    "</CONTEXT>\n",
    "\"\"\".strip()\n",
    "\n",
    "def build_prompt(query, search_results):\n",
    "    context = \"\"\n",
    "\n",
    "    for doc in search_results:\n",
    "        context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
    "    \n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e08724ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_results = search(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7c7597b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = build_prompt(question, search_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9ae3721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
      "Use only the facts from the CONTEXT when answering the QUESTION.\n",
      "\n",
      "<QUESTION>\n",
      "Can I still join in the course ?\n",
      "</QUESTION>\n",
      "\n",
      "<CONTEXT>\n",
      "section: General course-related questions\n",
      "question: Course - Can I still join the course after the start date?\n",
      "answer: Yes, even if you don't register, you're still eligible to submit the homeworks.\n",
      "Be aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Certificate - Can I follow the course in a self-paced mode and get a certificate?\n",
      "answer: No, you can only get a certificate if you finish the course with a “live” cohort. We don't award certificates for the self-paced mode. The reason is you need to peer-review capstone(s) after submitting a project. You can only peer-review projects at the time the course is running.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - Can I follow the course after it finishes?\n",
      "answer: Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\n",
      "You can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - When will the course start?\n",
      "answer: The purpose of this document is to capture frequently asked technical questions\n",
      "The exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\n",
      "Subscribe to course public Google Calendar (it works from Desktop only).\n",
      "Register before the course starts using this link.\n",
      "Join the course Telegram channel with announcements.\n",
      "Don’t forget to register in DataTalks.Club's Slack and join the channel.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - I have registered for the Data Engineering Bootcamp. When can I expect to receive the confirmation email?\n",
      "answer: You don't need it. You're accepted. You can also just start learning and submitting homework without registering. It is not checked against any registered list. Registration is just to gauge interest before the start date.\n",
      "\n",
      "\n",
      "</CONTEXT>\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "878c39fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()\n",
    "\n",
    "def llm(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model='gpt-4o-mini',\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6bebcedb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, you can still join the course after the start date. Even if you don't register, you are still eligible to submit the homework. However, be mindful of the deadlines for turning in the final projects.\n"
     ]
    }
   ],
   "source": [
    "answer = llm(prompt)\n",
    "\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fb32b6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(query):\n",
    "    # search \n",
    "    search_results = search(query)\n",
    "    # building the prompt\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    # getting llm response\n",
    "    answer = llm(prompt)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0dcfb189",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To run Kafka in Docker, follow these steps:\\n\\n1. Navigate to the folder containing your docker-compose YAML file.\\n2. Use the command `docker compose up -d` to start all the instances.\\n\\nMake sure to check if your Kafka broker Docker container is running by using `docker ps`. If you encounter any errors regarding availability, this might indicate that your Kafka broker is not working.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag(\"How do I run Kafka in docker ?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a284afd1",
   "metadata": {},
   "source": [
    "## Irrelevant Question \n",
    "\n",
    "we are asking our RAG to provide answer on that we don't have information about that in our Knowledge base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f02a2a41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, but there is no information provided in the context regarding how to patch KDE under FreeBSD. Please refer to relevant FreeBSD or KDE documentation for guidance.\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag(\"How do I patch KDE under FreeBSD?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ed93ee",
   "metadata": {},
   "source": [
    "### But, General LLM can answer it: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "91fdd40e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Patching KDE under FreeBSD involves a few steps, including obtaining the source code, applying the patch, and recompiling the software. Keep in mind that you should have the necessary development tools installed and that you're familiar with basic command-line operations. Here's a general guide on how to do this:\\n\\n### Prerequisites\\n\\n1. **Install Required Packages:**\\n   Make sure you have the necessary tools to build KDE. You can do this by installing `ports` and related packages, as well as the development tools:\\n\\n   ```sh\\n   pkg install ports\\n   pkg install git cmake gmake\\n   ```\\n\\n2. **Fetch the Source Code:**\\n   You can either download the source from the FreeBSD ports collection or clone it from the KDE repositories. Using ports is typically more straightforward on FreeBSD.\\n\\n   ```sh\\n   cd /usr/ports/x11/kde5\\n   ```\\n\\n3. **Update Ports Tree:**\\n   Ensure that your ports tree is up to date. You can use the `portsnap` tool:\\n\\n   ```sh\\n   portsnap fetch update\\n   ```\\n\\n### Applying the Patch\\n\\n1. **Change to Your Local Ports Directory:**\\n   Navigate to the directory of the KDE component you want to patch (e.g., `kde5`).\\n\\n2. **Obtain the Patch:**\\n   Get the patch you need. This could be a patch file provided by the KDE community or one that you created.\\n\\n3. **Apply the Patch:**\\n   You can use the `patch` command to apply the patch file. Use the following command:\\n\\n   ```sh\\n   patch < /path/to/your/patchfile.patch\\n   ```\\n\\n   Make sure you're in the right directory where the files to patch are located.\\n\\n### Rebuilding KDE\\n\\n1. **Build and Install:**\\n   Once the patch is applied, you can build the KDE component. This is done by running:\\n\\n   ```sh\\n   make install clean\\n   ```\\n\\n   This command will compile and install the patched version of KDE.\\n\\n2. **Start KDE:**\\n   Once the installation process is complete, you can start your KDE session. If you're using a display manager, it should recognize the new version.\\n\\n### Troubleshooting\\n\\n- If the patch fails to apply cleanly, you may need to manually resolve conflicts or modify the patch.\\n- Check the FreeBSD handbook or KDE community support channels for specific issues related to version compatibility.\\n\\n### Conclusion\\n\\nPatching KDE on FreeBSD requires you to be comfortable with building from source and using the command line. Make sure you have backups and proceed with caution, especially in a production environment. If you encounter issues, community forums and mailing lists can provide additional support.\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm(\"How do I patch KDE under FreeBSD?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1026c7",
   "metadata": {},
   "source": [
    "### Agentic RAG "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d71687d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You're a course teaching assistant.\n",
    "\n",
    "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
    "At the beginning the context is EMPTY.\n",
    "\n",
    "<QUESTION>\n",
    "{question}\n",
    "</QUESTION>\n",
    "\n",
    "<CONTEXT> \n",
    "{context}\n",
    "</CONTEXT>\n",
    "\n",
    "If CONTEXT is EMPTY, you can use our FAQ database.\n",
    "In this case, use the following output template:\n",
    "\n",
    "{{\n",
    "\"action\": \"SEARCH\",\n",
    "\"reasoning\": \"<add your reasoning here>\"\n",
    "}}\n",
    "\n",
    "If you can answer the QUESTION using CONTEXT, use this template:\n",
    "\n",
    "{{\n",
    "\"action\": \"ANSWER\",\n",
    "\"answer\": \"<your answer>\",\n",
    "\"source\": \"CONTEXT\"\n",
    "}}\n",
    "\n",
    "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
    "\n",
    "{{\n",
    "\"action\": \"ANSWER\",\n",
    "\"answer\": \"<your answer>\",\n",
    "\"source\": \"OWN_KNOWLEDGE\"\n",
    "}}\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b61c8f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"How can I run Docker in windows 10 ?\"\n",
    "\n",
    "context = \"EMPTY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d820b111",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = prompt_template.format(question=question, context=context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "20cd130e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're a course teaching assistant.\n",
      "\n",
      "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
      "At the beginning the context is EMPTY.\n",
      "\n",
      "<QUESTION>\n",
      "How can I run Docker in windows 10 ?\n",
      "</QUESTION>\n",
      "\n",
      "<CONTEXT> \n",
      "EMPTY\n",
      "</CONTEXT>\n",
      "\n",
      "If CONTEXT is EMPTY, you can use our FAQ database.\n",
      "In this case, use the following output template:\n",
      "\n",
      "{\n",
      "\"action\": \"SEARCH\",\n",
      "\"reasoning\": \"<add your reasoning here>\"\n",
      "}\n",
      "\n",
      "If you can answer the QUESTION using CONTEXT, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"CONTEXT\"\n",
      "}\n",
      "\n",
      "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "365e64bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = llm(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "441e55c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"To run Docker on Windows 10, you need to follow these steps: 1. Ensure your Windows 10 version is 64-bit and supports Hyper-V (Pro, Enterprise, or Education editions). 2. Download Docker Desktop from the official Docker website. 3. Install Docker Desktop by running the downloaded installer. During installation, enable the required features such as WSL 2 (Windows Subsystem for Linux) if prompted. 4. Once the installation is complete, restart your computer if necessary. 5. After rebooting, launch Docker Desktop and wait for it to initialize. 6. You can verify that Docker is running by opening a command prompt or PowerShell and executing the command `docker --version`. This should display the installed version of Docker. You can now use Docker on your Windows 10 machine.\",\n",
      "\"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bd3a752f",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Can I still join the course ?\"\n",
    "\n",
    "context = \"EMPTY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1bf78215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'action': 'SEARCH', 'reasoning': 'The question is about joining the course, and I need to check the FAQ for information regarding enrollment deadlines and eligibility.'}\n"
     ]
    }
   ],
   "source": [
    "prompt = prompt_template.format(question=question, context=context)\n",
    "\n",
    "answer_json = llm(prompt)\n",
    "\n",
    "answer = json.loads(answer_json)\n",
    "\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8e5c13db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bfb4c271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching...\n"
     ]
    }
   ],
   "source": [
    "# Now we can \n",
    "\n",
    "if answer['action'] == \"SEARCH\":\n",
    "    # we need to perform search\n",
    "    print(\"Searching...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cdb2d9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_context(search_results):\n",
    "    context = \"\"\n",
    "\n",
    "    for doc in search_results:\n",
    "        context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
    "\n",
    "    return context.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ee61ca7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're a course teaching assistant.\n",
      "\n",
      "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
      "At the beginning the context is EMPTY.\n",
      "\n",
      "<QUESTION>\n",
      "Can I still join the course ?\n",
      "</QUESTION>\n",
      "\n",
      "<CONTEXT> \n",
      "section: General course-related questions\n",
      "question: Course - Can I still join the course after the start date?\n",
      "answer: Yes, even if you don't register, you're still eligible to submit the homeworks.\n",
      "Be aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Certificate - Can I follow the course in a self-paced mode and get a certificate?\n",
      "answer: No, you can only get a certificate if you finish the course with a “live” cohort. We don't award certificates for the self-paced mode. The reason is you need to peer-review capstone(s) after submitting a project. You can only peer-review projects at the time the course is running.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - Can I follow the course after it finishes?\n",
      "answer: Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\n",
      "You can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - When will the course start?\n",
      "answer: The purpose of this document is to capture frequently asked technical questions\n",
      "The exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\n",
      "Subscribe to course public Google Calendar (it works from Desktop only).\n",
      "Register before the course starts using this link.\n",
      "Join the course Telegram channel with announcements.\n",
      "Don’t forget to register in DataTalks.Club's Slack and join the channel.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - I have registered for the Data Engineering Bootcamp. When can I expect to receive the confirmation email?\n",
      "answer: You don't need it. You're accepted. You can also just start learning and submitting homework without registering. It is not checked against any registered list. Registration is just to gauge interest before the start date.\n",
      "</CONTEXT>\n",
      "\n",
      "If CONTEXT is EMPTY, you can use our FAQ database.\n",
      "In this case, use the following output template:\n",
      "\n",
      "{\n",
      "\"action\": \"SEARCH\",\n",
      "\"reasoning\": \"<add your reasoning here>\"\n",
      "}\n",
      "\n",
      "If you can answer the QUESTION using CONTEXT, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"CONTEXT\"\n",
      "}\n",
      "\n",
      "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "search_results = search(question)\n",
    "\n",
    "context = build_context(search_results)\n",
    "\n",
    "prompt = prompt_template.format(question=question, context=context)\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c791d88c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"Yes, you can still join the course even after the start date. You are eligible to submit homework assignments, but be mindful that there are deadlines for final projects, so it's advisable to stay on track and not procrastinate.\",\n",
      "\"source\": \"CONTEXT\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "answer_json = llm(prompt)\n",
    "\n",
    "print(answer_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e0eaccb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agentic_rag_v1(question):\n",
    "    context = \"EMPTY\"\n",
    "    # prompt \n",
    "    prompt = prompt_template.format(question=question, context=context)\n",
    "    # llm response \n",
    "    answer_json = llm(prompt)\n",
    "    answer = json.loads(answer_json)\n",
    "    print(answer)\n",
    "\n",
    "    # search part\n",
    "    if answer['action'] == \"SEARCH\":\n",
    "        print(\"need to perform search\")\n",
    "        search_results = search(question)\n",
    "        context = build_context(search_results)\n",
    "\n",
    "        prompt = prompt_template.format(question=question, context=context)\n",
    "        answer_json = llm(prompt)\n",
    "        answer = json.loads(answer_json)\n",
    "        print(answer)\n",
    "\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c19fa7b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'action': 'SEARCH', 'reasoning': 'The CONTEXT is EMPTY, which means I need to check the FAQ database to find out about the enrollment status for the course.'}\n",
      "need to perform search\n",
      "{'action': 'ANSWER', 'answer': \"Yes, you can still join the course even after the start date. While it is recommended to register, you are eligible to submit the homework and participate in the course activities. Just keep in mind that there are deadlines for turning in final projects, so it's a good idea to stay on top of your assignments.\", 'source': 'CONTEXT'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'action': 'ANSWER',\n",
       " 'answer': \"Yes, you can still join the course even after the start date. While it is recommended to register, you are eligible to submit the homework and participate in the course activities. Just keep in mind that there are deadlines for turning in final projects, so it's a good idea to stay on top of your assignments.\",\n",
       " 'source': 'CONTEXT'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agentic_rag_v1(\"Can I still join the course ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e117d32b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'action': 'ANSWER', 'answer': \"To patch KDE under FreeBSD, you can follow these general steps: 1. First, ensure that you have the necessary tools installed, such as git and the FreeBSD ports or packages system. 2. Identify the specific package or port that you want to patch. You can find KDE ports under /usr/ports/x11/kde or similar directories. 3. Download the patch file that you want to apply. 4. Navigate to the directory of the specific KDE port you wish to modify. 5. Use the 'patch' command to apply the patch file, typically with a command like `patch < /path/to/your/patchfile.patch`. 6. Once the patch is applied, you can rebuild the port to ensure the changes take effect. Use `make install` or `portmaster` as needed. Check the FreeBSD Handbook or the KDE documentation for more detailed instructions and potential issues.\", 'source': 'OWN_KNOWLEDGE'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'action': 'ANSWER',\n",
       " 'answer': \"To patch KDE under FreeBSD, you can follow these general steps: 1. First, ensure that you have the necessary tools installed, such as git and the FreeBSD ports or packages system. 2. Identify the specific package or port that you want to patch. You can find KDE ports under /usr/ports/x11/kde or similar directories. 3. Download the patch file that you want to apply. 4. Navigate to the directory of the specific KDE port you wish to modify. 5. Use the 'patch' command to apply the patch file, typically with a command like `patch < /path/to/your/patchfile.patch`. 6. Once the patch is applied, you can rebuild the port to ensure the changes take effect. Use `make install` or `portmaster` as needed. Check the FreeBSD Handbook or the KDE documentation for more detailed instructions and potential issues.\",\n",
       " 'source': 'OWN_KNOWLEDGE'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agentic_rag_v1(\"how to patch KDE under FreeBSD?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8ac860",
   "metadata": {},
   "source": [
    "### Part 2: Agentic Search\n",
    "\n",
    "So far we had two actions only: `search` and `answer`. \n",
    "\n",
    "But we can let our `agent` formulate one or more search queries - and do it for a few iterations untill we found an answer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "02080254",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You're a course teaching assistant.\n",
    "\n",
    "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
    "\n",
    "The CONTEXT is build with the documents from our FAQ database.\n",
    "SEARCH_QUERIES contains the queries that were used to retrieve the documents\n",
    "from FAQ to and add them to the context.\n",
    "PREVIOUS_ACTIONS contains the actions you already performed.\n",
    "\n",
    "At the beginning the CONTEXT is empty.\n",
    "\n",
    "You can perform the following actions:\n",
    "\n",
    "- Search in the FAQ database to get more data for the CONTEXT\n",
    "- Answer the question using the CONTEXT\n",
    "- Answer the question using your own knowledge\n",
    "\n",
    "For the SEARCH action, build search requests based on the CONTEXT and the QUESTION.\n",
    "Carefully analyze the CONTEXT and generate the requests to deeply explore the topic. \n",
    "\n",
    "Don't use search queries used at the previous iterations.\n",
    "\n",
    "Don't repeat previously performed actions.\n",
    "\n",
    "Don't perform more than {max_iterations} iterations for a given student question.\n",
    "The current iteration number: {iteration_number}. If we exceed the allowed number \n",
    "of iterations, give the best possible answer with the provided information.\n",
    "\n",
    "Output templates:\n",
    "\n",
    "If you want to perform search, use this template:\n",
    "\n",
    "{{\n",
    "\"action\": \"SEARCH\",\n",
    "\"reasoning\": \"<add your reasoning here>\",\n",
    "\"keywords\": [\"search query 1\", \"search query 2\", ...]\n",
    "}}\n",
    "\n",
    "If you can answer the QUESTION using CONTEXT, use this template:\n",
    "\n",
    "{{\n",
    "\"action\": \"ANSWER_CONTEXT\",\n",
    "\"answer\": \"<your answer>\",\n",
    "\"source\": \"CONTEXT\"\n",
    "}}\n",
    "\n",
    "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
    "\n",
    "{{\n",
    "\"action\": \"ANSWER\",\n",
    "\"answer\": \"<your answer>\",\n",
    "\"source\": \"OWN_KNOWLEDGE\"\n",
    "}}\n",
    "\n",
    "<QUESTION>\n",
    "{question}\n",
    "</QUESTION>\n",
    "\n",
    "<SEARCH_QUERIES>\n",
    "{search_queries}\n",
    "</SEARCH_QUERIES>\n",
    "\n",
    "<CONTEXT> \n",
    "{context}\n",
    "</CONTEXT>\n",
    "\n",
    "<PREVIOUS_ACTIONS>\n",
    "{previous_actions}\n",
    "</PREVIOUS_ACTIONS>\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e54bc99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"How do I do well on module 1?\"\n",
    "\n",
    "context = \"EMPTY\"\n",
    "\n",
    "max_iterations = 3 \n",
    "\n",
    "iteration_number = 0 \n",
    "\n",
    "search_queries = []\n",
    "\n",
    "search_results = []\n",
    "\n",
    "previous_actions = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5614cdb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = build_context(search_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4c715759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're a course teaching assistant.\n",
      "\n",
      "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
      "\n",
      "The CONTEXT is build with the documents from our FAQ database.\n",
      "SEARCH_QUERIES contains the queries that were used to retrieve the documents\n",
      "from FAQ to and add them to the context.\n",
      "PREVIOUS_ACTIONS contains the actions you already performed.\n",
      "\n",
      "At the beginning the CONTEXT is empty.\n",
      "\n",
      "You can perform the following actions:\n",
      "\n",
      "- Search in the FAQ database to get more data for the CONTEXT\n",
      "- Answer the question using the CONTEXT\n",
      "- Answer the question using your own knowledge\n",
      "\n",
      "For the SEARCH action, build search requests based on the CONTEXT and the QUESTION.\n",
      "Carefully analyze the CONTEXT and generate the requests to deeply explore the topic. \n",
      "\n",
      "Don't use search queries used at the previous iterations.\n",
      "\n",
      "Don't repeat previously performed actions.\n",
      "\n",
      "Don't perform more than 3 iterations for a given student question.\n",
      "The current iteration number: 0. If we exceed the allowed number \n",
      "of iterations, give the best possible answer with the provided information.\n",
      "\n",
      "Output templates:\n",
      "\n",
      "If you want to perform search, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"SEARCH\",\n",
      "\"reasoning\": \"<add your reasoning here>\",\n",
      "\"keywords\": [\"search query 1\", \"search query 2\", ...]\n",
      "}\n",
      "\n",
      "If you can answer the QUESTION using CONTEXT, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER_CONTEXT\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"CONTEXT\"\n",
      "}\n",
      "\n",
      "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n",
      "\n",
      "<QUESTION>\n",
      "How do I do well on module 1?\n",
      "</QUESTION>\n",
      "\n",
      "<SEARCH_QUERIES>\n",
      "\n",
      "</SEARCH_QUERIES>\n",
      "\n",
      "<CONTEXT> \n",
      "\n",
      "</CONTEXT>\n",
      "\n",
      "<PREVIOUS_ACTIONS>\n",
      "\n",
      "</PREVIOUS_ACTIONS>\n"
     ]
    }
   ],
   "source": [
    "prompt = prompt_template.format(\n",
    "    question=question,\n",
    "    context=context,\n",
    "    search_queries=\"\\n\".join(search_queries),\n",
    "    previous_actions='\\n'.join([json.dumps(a) for a in previous_actions]),\n",
    "    max_iterations=max_iterations,\n",
    "    iteration_number=iteration_number\n",
    ")\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0d59477e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "\"action\": \"SEARCH\",\n",
      "\"reasoning\": \"The question asks for specific strategies or recommendations on how to perform well in module 1. It's beneficial to gather insights or advice related to study tips, module objectives, or common challenges faced by students in this module.\",\n",
      "\"keywords\": [\"how to succeed in module 1\", \"study tips for module 1\", \"module 1 overview\", \"common challenges in module 1\"]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "answer_json = llm(prompt)\n",
    "\n",
    "print(answer_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4b367939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'action': 'SEARCH',\n",
       " 'reasoning': \"The question asks for specific strategies or recommendations on how to perform well in module 1. It's beneficial to gather insights or advice related to study tips, module objectives, or common challenges faced by students in this module.\",\n",
       " 'keywords': ['how to succeed in module 1',\n",
       "  'study tips for module 1',\n",
       "  'module 1 overview',\n",
       "  'common challenges in module 1']}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer = json.loads(answer_json)\n",
    "\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bbd3a014",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = answer['keywords']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "47567a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looping on queries\n",
    "for kw in keywords:\n",
    "    # keeping history of search queries\n",
    "    search_queries.append(kw)\n",
    "    # Performing search on each query (kw)\n",
    "    s_r = search(kw)\n",
    "    # similary history for search results\n",
    "    search_results.extend(s_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5af61bc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['how to succeed in module 1',\n",
       " 'study tips for module 1',\n",
       " 'module 1 overview',\n",
       " 'common challenges in module 1']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a9ebaa90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'You need to look for the Py4J file and note the version of the filename. Once you know the version, you can update the export command accordingly, this is how you check yours:\\n` ls ${SPARK_HOME}/python/lib/ ` and then you add it in the export command, mine was:\\nexport PYTHONPATH=”${SPARK_HOME}/python/lib/Py4J-0.10.9.5-src.zip:${PYTHONPATH}”\\nMake sure that the version under `${SPARK_HOME}/python/lib/` matches the filename of py4j or you will encounter `ModuleNotFoundError: No module named \\'py4j\\'` while executing `import pyspark`.\\nFor instance, if the file under `${SPARK_HOME}/python/lib/` was `py4j-0.10.9.3-src.zip`.\\nThen the export PYTHONPATH statement above should be changed to `export PYTHONPATH=\"${SPARK_HOME}/python/lib/py4j-0.10.9.3-src.zip:$PYTHONPATH\"` appropriately.\\nAdditionally, you can check for the version of ‘py4j’ of the spark you’re using from here and update as mentioned above.\\n~ Abhijit Chakraborty: Sometimes, even with adding the correct version of py4j might not solve the problem. Simply run pip install py4j and problem should be resolved.',\n",
       "  'section': 'Module 5: pyspark',\n",
       "  'question': \"Py4JJavaError - ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`\",\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  '_id': 323},\n",
       " {'text': \"Following dbt with BigQuery on Docker readme.md, after `docker-compose build` and `docker-compose run dbt-bq-dtc init`, encountered error `ModuleNotFoundError: No module named 'pytz'`\\nSolution:\\nAdd `RUN python -m pip install --no-cache pytz` in the Dockerfile under `FROM --platform=$build_for python:3.9.9-slim-bullseye as base`\",\n",
       "  'section': 'Module 4: analytics engineering with dbt',\n",
       "  'question': \"DBT - Error: No module named 'pytz' while setting up dbt with docker\",\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  '_id': 299},\n",
       " {'text': 'Even after installing pyspark correctly on linux machine (VM ) as per course instructions, faced a module not found error in jupyter notebook .\\nThe solution which worked for me(use following in jupyter notebook) :\\n!pip install findspark\\nimport findspark\\nfindspark.init()\\nThereafter , import pyspark and create spark contex<<t as usual\\nNone of the solutions above worked for me till I ran !pip3 install pyspark instead !pip install pyspark.\\nFilter based on conditions based on multiple columns\\nfrom pyspark.sql.functions import col\\nnew_final.filter((new_final.a_zone==\"Murray Hill\") & (new_final.b_zone==\"Midwood\")).show()\\nKrishna Anand',\n",
       "  'section': 'Module 5: pyspark',\n",
       "  'question': 'Module Not Found Error in Jupyter Notebook .',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  '_id': 322}]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_results[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cb37cdb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 20)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(search_queries), len(search_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ac34e0",
   "metadata": {},
   "source": [
    "4 * 5 = 20 \n",
    "\n",
    "for each query, we have 5 search results...\n",
    "\n",
    "Problem: search results might be redundant.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2f24ad7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## to remove duplicates from the search_results\n",
    "def dedup(seq):\n",
    "    seen = set()\n",
    "    result = []\n",
    "    for el in seq:\n",
    "        _id = el['_id']\n",
    "        if _id in seen:\n",
    "            continue\n",
    "        seen.add(_id)\n",
    "        result.append(el)\n",
    "    return result\n",
    "\n",
    "search_results = dedup(search_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0ec13287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(search_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f6dac3",
   "metadata": {},
   "source": [
    "Now we have only 6 search results, out of 20... "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2de527c",
   "metadata": {},
   "source": [
    "Previous Actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6fdfd29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keeping history of previous actions\n",
    "previous_actions.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "722b4de6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'action': 'SEARCH',\n",
       "  'reasoning': \"The question asks for specific strategies or recommendations on how to perform well in module 1. It's beneficial to gather insights or advice related to study tips, module objectives, or common challenges faced by students in this module.\",\n",
       "  'keywords': ['how to succeed in module 1',\n",
       "   'study tips for module 1',\n",
       "   'module 1 overview',\n",
       "   'common challenges in module 1']}]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previous_actions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3688741f",
   "metadata": {},
   "source": [
    "Now let's rerun the Agentic Search loop once again..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e63fb381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're a course teaching assistant.\n",
      "\n",
      "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
      "\n",
      "The CONTEXT is build with the documents from our FAQ database.\n",
      "SEARCH_QUERIES contains the queries that were used to retrieve the documents\n",
      "from FAQ to and add them to the context.\n",
      "PREVIOUS_ACTIONS contains the actions you already performed.\n",
      "\n",
      "At the beginning the CONTEXT is empty.\n",
      "\n",
      "You can perform the following actions:\n",
      "\n",
      "- Search in the FAQ database to get more data for the CONTEXT\n",
      "- Answer the question using the CONTEXT\n",
      "- Answer the question using your own knowledge\n",
      "\n",
      "For the SEARCH action, build search requests based on the CONTEXT and the QUESTION.\n",
      "Carefully analyze the CONTEXT and generate the requests to deeply explore the topic. \n",
      "\n",
      "Don't use search queries used at the previous iterations.\n",
      "\n",
      "Don't repeat previously performed actions.\n",
      "\n",
      "Don't perform more than 3 iterations for a given student question.\n",
      "The current iteration number: 1. If we exceed the allowed number \n",
      "of iterations, give the best possible answer with the provided information.\n",
      "\n",
      "Output templates:\n",
      "\n",
      "If you want to perform search, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"SEARCH\",\n",
      "\"reasoning\": \"<add your reasoning here>\",\n",
      "\"keywords\": [\"search query 1\", \"search query 2\", ...]\n",
      "}\n",
      "\n",
      "If you can answer the QUESTION using CONTEXT, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER_CONTEXT\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"CONTEXT\"\n",
      "}\n",
      "\n",
      "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n",
      "\n",
      "<QUESTION>\n",
      "How do I do well on module 1?\n",
      "</QUESTION>\n",
      "\n",
      "<SEARCH_QUERIES>\n",
      "how to succeed in module 1\n",
      "study tips for module 1\n",
      "module 1 overview\n",
      "common challenges in module 1\n",
      "</SEARCH_QUERIES>\n",
      "\n",
      "<CONTEXT> \n",
      "section: Module 5: pyspark\n",
      "question: Py4JJavaError - ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`\n",
      "answer: You need to look for the Py4J file and note the version of the filename. Once you know the version, you can update the export command accordingly, this is how you check yours:\n",
      "` ls ${SPARK_HOME}/python/lib/ ` and then you add it in the export command, mine was:\n",
      "export PYTHONPATH=”${SPARK_HOME}/python/lib/Py4J-0.10.9.5-src.zip:${PYTHONPATH}”\n",
      "Make sure that the version under `${SPARK_HOME}/python/lib/` matches the filename of py4j or you will encounter `ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`.\n",
      "For instance, if the file under `${SPARK_HOME}/python/lib/` was `py4j-0.10.9.3-src.zip`.\n",
      "Then the export PYTHONPATH statement above should be changed to `export PYTHONPATH=\"${SPARK_HOME}/python/lib/py4j-0.10.9.3-src.zip:$PYTHONPATH\"` appropriately.\n",
      "Additionally, you can check for the version of ‘py4j’ of the spark you’re using from here and update as mentioned above.\n",
      "~ Abhijit Chakraborty: Sometimes, even with adding the correct version of py4j might not solve the problem. Simply run pip install py4j and problem should be resolved.\n",
      "\n",
      "section: Module 4: analytics engineering with dbt\n",
      "question: DBT - Error: No module named 'pytz' while setting up dbt with docker\n",
      "answer: Following dbt with BigQuery on Docker readme.md, after `docker-compose build` and `docker-compose run dbt-bq-dtc init`, encountered error `ModuleNotFoundError: No module named 'pytz'`\n",
      "Solution:\n",
      "Add `RUN python -m pip install --no-cache pytz` in the Dockerfile under `FROM --platform=$build_for python:3.9.9-slim-bullseye as base`\n",
      "\n",
      "section: Module 5: pyspark\n",
      "question: Module Not Found Error in Jupyter Notebook .\n",
      "answer: Even after installing pyspark correctly on linux machine (VM ) as per course instructions, faced a module not found error in jupyter notebook .\n",
      "The solution which worked for me(use following in jupyter notebook) :\n",
      "!pip install findspark\n",
      "import findspark\n",
      "findspark.init()\n",
      "Thereafter , import pyspark and create spark contex<<t as usual\n",
      "None of the solutions above worked for me till I ran !pip3 install pyspark instead !pip install pyspark.\n",
      "Filter based on conditions based on multiple columns\n",
      "from pyspark.sql.functions import col\n",
      "new_final.filter((new_final.a_zone==\"Murray Hill\") & (new_final.b_zone==\"Midwood\")).show()\n",
      "Krishna Anand\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Postgres - ModuleNotFoundError: No module named 'psycopg2'\n",
      "answer: Issue:\n",
      "e…\n",
      "Solution:\n",
      "pip install psycopg2-binary\n",
      "If you already have it, you might need to update it:\n",
      "pip install psycopg2-binary --upgrade\n",
      "Other methods, if the above fails:\n",
      "if you are getting the “ ModuleNotFoundError: No module named 'psycopg2' “ error even after the above installation, then try updating conda using the command conda update -n base -c defaults conda. Or if you are using pip, then try updating it before installing the psycopg packages i.e\n",
      "First uninstall the psycopg package\n",
      "Then update conda or pip\n",
      "Then install psycopg again using pip.\n",
      "if you are still facing error with r pcycopg2 and showing pg_config not found then you will have to install postgresql. in MAC it is brew install postgresql\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Python - SQLALchemy - TypeError 'module' object is not callable\n",
      "answer: create_engine('postgresql://root:root@localhost:5432/ny_taxi')  I get the error \"TypeError: 'module' object is not callable\"\n",
      "Solution:\n",
      "conn_string = \"postgresql+psycopg://root:root@localhost:5432/ny_taxi\"\n",
      "engine = create_engine(conn_string)\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Python - SQLAlchemy - ModuleNotFoundError: No module named 'psycopg2'.\n",
      "answer: Error raised during the jupyter notebook’s cell execution:\n",
      "engine = create_engine('postgresql://root:root@localhost:5432/ny_taxi').\n",
      "Solution: Need to install Python module “psycopg2”. Can be installed by Conda or pip.\n",
      "</CONTEXT>\n",
      "\n",
      "<PREVIOUS_ACTIONS>\n",
      "{\"action\": \"SEARCH\", \"reasoning\": \"The question asks for specific strategies or recommendations on how to perform well in module 1. It's beneficial to gather insights or advice related to study tips, module objectives, or common challenges faced by students in this module.\", \"keywords\": [\"how to succeed in module 1\", \"study tips for module 1\", \"module 1 overview\", \"common challenges in module 1\"]}\n",
      "</PREVIOUS_ACTIONS>\n"
     ]
    }
   ],
   "source": [
    "iteration_number = 1 \n",
    "\n",
    "\n",
    "context = build_context(search_results)\n",
    "\n",
    "prompt = prompt_template.format(\n",
    "    question=question,\n",
    "    context=context,\n",
    "    search_queries=\"\\n\".join(search_queries),\n",
    "    previous_actions='\\n'.join([json.dumps(a) for a in previous_actions]),\n",
    "    max_iterations=max_iterations,\n",
    "    iteration_number=iteration_number\n",
    ")\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "428a9f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "\"action\": \"SEARCH\",\n",
      "\"reasoning\": \"I need to collect more specific information related to study tips and effective practices for succeeding in module 1, as well as any common challenges students might face in this module to provide a tailored response.\",\n",
      "\"keywords\": [\"success strategies for module 1\", \"effective study techniques for module 1\", \"module 1 common pitfalls\", \"best practices for module 1\"]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "answer_json = llm(prompt)\n",
    "\n",
    "print(answer_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3184248e",
   "metadata": {},
   "source": [
    "### Iteration-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5c1951ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'action': 'SEARCH',\n",
       " 'reasoning': 'I need to collect more specific information related to study tips and effective practices for succeeding in module 1, as well as any common challenges students might face in this module to provide a tailored response.',\n",
       " 'keywords': ['success strategies for module 1',\n",
       "  'effective study techniques for module 1',\n",
       "  'module 1 common pitfalls',\n",
       "  'best practices for module 1']}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer = json.loads(answer_json)\n",
    "\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2b33d475",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = answer['keywords']\n",
    "\n",
    "# Looping on queries\n",
    "for kw in keywords:\n",
    "    # keeping history of search queries\n",
    "    search_queries.append(kw)\n",
    "    # Performing search on each query (kw)\n",
    "    s_r = search(kw)\n",
    "    # similary history for search results\n",
    "    search_results.extend(s_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "00a00032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 26)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(search_queries), len(search_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9657d241",
   "metadata": {},
   "outputs": [],
   "source": [
    "## to remove duplicates from the search_results\n",
    "def dedup(seq):\n",
    "    seen = set()\n",
    "    result = []\n",
    "    for el in seq:\n",
    "        _id = el['_id']\n",
    "        if _id in seen:\n",
    "            continue\n",
    "        seen.add(_id)\n",
    "        result.append(el)\n",
    "    return result\n",
    "\n",
    "search_results = dedup(search_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2881cb62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 7)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(search_queries), len(search_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "269c5f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keeping history of previous actions\n",
    "previous_actions.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c36de063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're a course teaching assistant.\n",
      "\n",
      "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
      "\n",
      "The CONTEXT is build with the documents from our FAQ database.\n",
      "SEARCH_QUERIES contains the queries that were used to retrieve the documents\n",
      "from FAQ to and add them to the context.\n",
      "PREVIOUS_ACTIONS contains the actions you already performed.\n",
      "\n",
      "At the beginning the CONTEXT is empty.\n",
      "\n",
      "You can perform the following actions:\n",
      "\n",
      "- Search in the FAQ database to get more data for the CONTEXT\n",
      "- Answer the question using the CONTEXT\n",
      "- Answer the question using your own knowledge\n",
      "\n",
      "For the SEARCH action, build search requests based on the CONTEXT and the QUESTION.\n",
      "Carefully analyze the CONTEXT and generate the requests to deeply explore the topic. \n",
      "\n",
      "Don't use search queries used at the previous iterations.\n",
      "\n",
      "Don't repeat previously performed actions.\n",
      "\n",
      "Don't perform more than 3 iterations for a given student question.\n",
      "The current iteration number: 2. If we exceed the allowed number \n",
      "of iterations, give the best possible answer with the provided information.\n",
      "\n",
      "Output templates:\n",
      "\n",
      "If you want to perform search, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"SEARCH\",\n",
      "\"reasoning\": \"<add your reasoning here>\",\n",
      "\"keywords\": [\"search query 1\", \"search query 2\", ...]\n",
      "}\n",
      "\n",
      "If you can answer the QUESTION using CONTEXT, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER_CONTEXT\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"CONTEXT\"\n",
      "}\n",
      "\n",
      "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n",
      "\n",
      "<QUESTION>\n",
      "How do I do well on module 1?\n",
      "</QUESTION>\n",
      "\n",
      "<SEARCH_QUERIES>\n",
      "how to succeed in module 1\n",
      "study tips for module 1\n",
      "module 1 overview\n",
      "common challenges in module 1\n",
      "success strategies for module 1\n",
      "effective study techniques for module 1\n",
      "module 1 common pitfalls\n",
      "best practices for module 1\n",
      "</SEARCH_QUERIES>\n",
      "\n",
      "<CONTEXT> \n",
      "section: Module 5: pyspark\n",
      "question: Py4JJavaError - ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`\n",
      "answer: You need to look for the Py4J file and note the version of the filename. Once you know the version, you can update the export command accordingly, this is how you check yours:\n",
      "` ls ${SPARK_HOME}/python/lib/ ` and then you add it in the export command, mine was:\n",
      "export PYTHONPATH=”${SPARK_HOME}/python/lib/Py4J-0.10.9.5-src.zip:${PYTHONPATH}”\n",
      "Make sure that the version under `${SPARK_HOME}/python/lib/` matches the filename of py4j or you will encounter `ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`.\n",
      "For instance, if the file under `${SPARK_HOME}/python/lib/` was `py4j-0.10.9.3-src.zip`.\n",
      "Then the export PYTHONPATH statement above should be changed to `export PYTHONPATH=\"${SPARK_HOME}/python/lib/py4j-0.10.9.3-src.zip:$PYTHONPATH\"` appropriately.\n",
      "Additionally, you can check for the version of ‘py4j’ of the spark you’re using from here and update as mentioned above.\n",
      "~ Abhijit Chakraborty: Sometimes, even with adding the correct version of py4j might not solve the problem. Simply run pip install py4j and problem should be resolved.\n",
      "\n",
      "section: Module 4: analytics engineering with dbt\n",
      "question: DBT - Error: No module named 'pytz' while setting up dbt with docker\n",
      "answer: Following dbt with BigQuery on Docker readme.md, after `docker-compose build` and `docker-compose run dbt-bq-dtc init`, encountered error `ModuleNotFoundError: No module named 'pytz'`\n",
      "Solution:\n",
      "Add `RUN python -m pip install --no-cache pytz` in the Dockerfile under `FROM --platform=$build_for python:3.9.9-slim-bullseye as base`\n",
      "\n",
      "section: Module 5: pyspark\n",
      "question: Module Not Found Error in Jupyter Notebook .\n",
      "answer: Even after installing pyspark correctly on linux machine (VM ) as per course instructions, faced a module not found error in jupyter notebook .\n",
      "The solution which worked for me(use following in jupyter notebook) :\n",
      "!pip install findspark\n",
      "import findspark\n",
      "findspark.init()\n",
      "Thereafter , import pyspark and create spark contex<<t as usual\n",
      "None of the solutions above worked for me till I ran !pip3 install pyspark instead !pip install pyspark.\n",
      "Filter based on conditions based on multiple columns\n",
      "from pyspark.sql.functions import col\n",
      "new_final.filter((new_final.a_zone==\"Murray Hill\") & (new_final.b_zone==\"Midwood\")).show()\n",
      "Krishna Anand\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Postgres - ModuleNotFoundError: No module named 'psycopg2'\n",
      "answer: Issue:\n",
      "e…\n",
      "Solution:\n",
      "pip install psycopg2-binary\n",
      "If you already have it, you might need to update it:\n",
      "pip install psycopg2-binary --upgrade\n",
      "Other methods, if the above fails:\n",
      "if you are getting the “ ModuleNotFoundError: No module named 'psycopg2' “ error even after the above installation, then try updating conda using the command conda update -n base -c defaults conda. Or if you are using pip, then try updating it before installing the psycopg packages i.e\n",
      "First uninstall the psycopg package\n",
      "Then update conda or pip\n",
      "Then install psycopg again using pip.\n",
      "if you are still facing error with r pcycopg2 and showing pg_config not found then you will have to install postgresql. in MAC it is brew install postgresql\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Python - SQLALchemy - TypeError 'module' object is not callable\n",
      "answer: create_engine('postgresql://root:root@localhost:5432/ny_taxi')  I get the error \"TypeError: 'module' object is not callable\"\n",
      "Solution:\n",
      "conn_string = \"postgresql+psycopg://root:root@localhost:5432/ny_taxi\"\n",
      "engine = create_engine(conn_string)\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Python - SQLAlchemy - ModuleNotFoundError: No module named 'psycopg2'.\n",
      "answer: Error raised during the jupyter notebook’s cell execution:\n",
      "engine = create_engine('postgresql://root:root@localhost:5432/ny_taxi').\n",
      "Solution: Need to install Python module “psycopg2”. Can be installed by Conda or pip.\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Docker - cs to store all code in your default Linux distro to get the best out of file system performance (since Docker runs on WSL2 backend by default for Windows 10 Home / Windows 11 Home users).\n",
      "answer: More info in the Docker Docs on Best Practises\n",
      "</CONTEXT>\n",
      "\n",
      "<PREVIOUS_ACTIONS>\n",
      "{\"action\": \"SEARCH\", \"reasoning\": \"The question asks for specific strategies or recommendations on how to perform well in module 1. It's beneficial to gather insights or advice related to study tips, module objectives, or common challenges faced by students in this module.\", \"keywords\": [\"how to succeed in module 1\", \"study tips for module 1\", \"module 1 overview\", \"common challenges in module 1\"]}\n",
      "{\"action\": \"SEARCH\", \"reasoning\": \"I need to collect more specific information related to study tips and effective practices for succeeding in module 1, as well as any common challenges students might face in this module to provide a tailored response.\", \"keywords\": [\"success strategies for module 1\", \"effective study techniques for module 1\", \"module 1 common pitfalls\", \"best practices for module 1\"]}\n",
      "</PREVIOUS_ACTIONS>\n"
     ]
    }
   ],
   "source": [
    "iteration_number = 2\n",
    "\n",
    "\n",
    "context = build_context(search_results)\n",
    "\n",
    "prompt = prompt_template.format(\n",
    "    question=question,\n",
    "    context=context,\n",
    "    search_queries=\"\\n\".join(search_queries),\n",
    "    previous_actions='\\n'.join([json.dumps(a) for a in previous_actions]),\n",
    "    max_iterations=max_iterations,\n",
    "    iteration_number=iteration_number\n",
    ")\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9e87330a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'action': 'ANSWER', 'answer': \"To do well in Module 1, 'Docker and Terraform', focus on understanding the core concepts of both technologies. Here are some study tips:\\n\\n1. **Hands-On Practice**: Set up your own Docker containers and use Terraform to manage infrastructure as code. Real-world practice will solidify your understanding.\\n2. **Follow Documentation**: Ensure you read and understand the official documentation for both Docker and Terraform. They contain valuable insights and best practices.\\n3. **Engage in Community**: Participate in community forums or study groups. This can help you resolve doubts and learn from peers' experiences.\\n4. **Understand Common Issues**: Familiarize yourself with common pitfalls and errors, such as module not found errors or configuration issues that students often encounter. Learning how to troubleshoot these will prepare you for exams and projects.\\n5. **Review Course Materials**: Go over video lectures and course notes thoroughly. Pay attention to any assignments or practical applications discussed during class.\\n\\nBy combining these strategies, you can enhance your comprehension and performance in this module.\", 'source': 'OWN_KNOWLEDGE'}\n"
     ]
    }
   ],
   "source": [
    "answer_json = llm(prompt)\n",
    "\n",
    "answer = json.loads(answer_json)\n",
    "\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "26e84548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To do well in Module 1, 'Docker and Terraform', focus on understanding the core concepts of both technologies. Here are some study tips:\n",
      "\n",
      "1. **Hands-On Practice**: Set up your own Docker containers and use Terraform to manage infrastructure as code. Real-world practice will solidify your understanding.\n",
      "2. **Follow Documentation**: Ensure you read and understand the official documentation for both Docker and Terraform. They contain valuable insights and best practices.\n",
      "3. **Engage in Community**: Participate in community forums or study groups. This can help you resolve doubts and learn from peers' experiences.\n",
      "4. **Understand Common Issues**: Familiarize yourself with common pitfalls and errors, such as module not found errors or configuration issues that students often encounter. Learning how to troubleshoot these will prepare you for exams and projects.\n",
      "5. **Review Course Materials**: Go over video lectures and course notes thoroughly. Pay attention to any assignments or practical applications discussed during class.\n",
      "\n",
      "By combining these strategies, you can enhance your comprehension and performance in this module.\n"
     ]
    }
   ],
   "source": [
    "print(answer['answer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7072b1",
   "metadata": {},
   "source": [
    "### Agentic Search Function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8109198c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agentic_search(question):\n",
    "    search_queries = []\n",
    "    search_results = []\n",
    "    previous_actions = []\n",
    "\n",
    "    iteration = 0\n",
    "    \n",
    "    while True:\n",
    "        print(f'ITERATION #{iteration}...')\n",
    "    \n",
    "        context = build_context(search_results)\n",
    "        prompt = prompt_template.format(\n",
    "            question=question,\n",
    "            context=context,\n",
    "            search_queries=\"\\n\".join(search_queries),\n",
    "            previous_actions='\\n'.join([json.dumps(a) for a in previous_actions]),\n",
    "            max_iterations=3,\n",
    "            iteration_number=iteration\n",
    "        )\n",
    "    \n",
    "        print(prompt)\n",
    "    \n",
    "        answer_json = llm(prompt)\n",
    "        answer = json.loads(answer_json)\n",
    "        print(json.dumps(answer, indent=2))\n",
    "\n",
    "        previous_actions.append(answer)\n",
    "    \n",
    "        action = answer['action']\n",
    "        if action != 'SEARCH':\n",
    "            break\n",
    "    \n",
    "        keywords = answer['keywords']\n",
    "        search_queries = list(set(search_queries) | set(keywords))\n",
    "\n",
    "        for k in keywords:\n",
    "            res = search(k)\n",
    "            search_results.extend(res)\n",
    "    \n",
    "        search_results = dedup(search_results)\n",
    "        \n",
    "        iteration = iteration + 1\n",
    "        if iteration >= 4:\n",
    "            break\n",
    "    \n",
    "        print()\n",
    "\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1f5c09a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITERATION #0...\n",
      "You're a course teaching assistant.\n",
      "\n",
      "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
      "\n",
      "The CONTEXT is build with the documents from our FAQ database.\n",
      "SEARCH_QUERIES contains the queries that were used to retrieve the documents\n",
      "from FAQ to and add them to the context.\n",
      "PREVIOUS_ACTIONS contains the actions you already performed.\n",
      "\n",
      "At the beginning the CONTEXT is empty.\n",
      "\n",
      "You can perform the following actions:\n",
      "\n",
      "- Search in the FAQ database to get more data for the CONTEXT\n",
      "- Answer the question using the CONTEXT\n",
      "- Answer the question using your own knowledge\n",
      "\n",
      "For the SEARCH action, build search requests based on the CONTEXT and the QUESTION.\n",
      "Carefully analyze the CONTEXT and generate the requests to deeply explore the topic. \n",
      "\n",
      "Don't use search queries used at the previous iterations.\n",
      "\n",
      "Don't repeat previously performed actions.\n",
      "\n",
      "Don't perform more than 3 iterations for a given student question.\n",
      "The current iteration number: 0. If we exceed the allowed number \n",
      "of iterations, give the best possible answer with the provided information.\n",
      "\n",
      "Output templates:\n",
      "\n",
      "If you want to perform search, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"SEARCH\",\n",
      "\"reasoning\": \"<add your reasoning here>\",\n",
      "\"keywords\": [\"search query 1\", \"search query 2\", ...]\n",
      "}\n",
      "\n",
      "If you can answer the QUESTION using CONTEXT, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER_CONTEXT\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"CONTEXT\"\n",
      "}\n",
      "\n",
      "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n",
      "\n",
      "<QUESTION>\n",
      "what do I need to do to be successful at module 1?\n",
      "</QUESTION>\n",
      "\n",
      "<SEARCH_QUERIES>\n",
      "\n",
      "</SEARCH_QUERIES>\n",
      "\n",
      "<CONTEXT> \n",
      "\n",
      "</CONTEXT>\n",
      "\n",
      "<PREVIOUS_ACTIONS>\n",
      "\n",
      "</PREVIOUS_ACTIONS>\n",
      "{\n",
      "  \"action\": \"SEARCH\",\n",
      "  \"reasoning\": \"To provide a comprehensive answer about success in module 1, I need to gather detailed guidelines or tips that relate specifically to that module from the FAQ database.\",\n",
      "  \"keywords\": [\n",
      "    \"module 1 success tips\",\n",
      "    \"how to succeed in module 1\",\n",
      "    \"module 1 requirements\"\n",
      "  ]\n",
      "}\n",
      "\n",
      "ITERATION #1...\n",
      "You're a course teaching assistant.\n",
      "\n",
      "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
      "\n",
      "The CONTEXT is build with the documents from our FAQ database.\n",
      "SEARCH_QUERIES contains the queries that were used to retrieve the documents\n",
      "from FAQ to and add them to the context.\n",
      "PREVIOUS_ACTIONS contains the actions you already performed.\n",
      "\n",
      "At the beginning the CONTEXT is empty.\n",
      "\n",
      "You can perform the following actions:\n",
      "\n",
      "- Search in the FAQ database to get more data for the CONTEXT\n",
      "- Answer the question using the CONTEXT\n",
      "- Answer the question using your own knowledge\n",
      "\n",
      "For the SEARCH action, build search requests based on the CONTEXT and the QUESTION.\n",
      "Carefully analyze the CONTEXT and generate the requests to deeply explore the topic. \n",
      "\n",
      "Don't use search queries used at the previous iterations.\n",
      "\n",
      "Don't repeat previously performed actions.\n",
      "\n",
      "Don't perform more than 3 iterations for a given student question.\n",
      "The current iteration number: 1. If we exceed the allowed number \n",
      "of iterations, give the best possible answer with the provided information.\n",
      "\n",
      "Output templates:\n",
      "\n",
      "If you want to perform search, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"SEARCH\",\n",
      "\"reasoning\": \"<add your reasoning here>\",\n",
      "\"keywords\": [\"search query 1\", \"search query 2\", ...]\n",
      "}\n",
      "\n",
      "If you can answer the QUESTION using CONTEXT, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER_CONTEXT\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"CONTEXT\"\n",
      "}\n",
      "\n",
      "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n",
      "\n",
      "<QUESTION>\n",
      "what do I need to do to be successful at module 1?\n",
      "</QUESTION>\n",
      "\n",
      "<SEARCH_QUERIES>\n",
      "module 1 requirements\n",
      "how to succeed in module 1\n",
      "module 1 success tips\n",
      "</SEARCH_QUERIES>\n",
      "\n",
      "<CONTEXT> \n",
      "section: Module 5: pyspark\n",
      "question: Module Not Found Error in Jupyter Notebook .\n",
      "answer: Even after installing pyspark correctly on linux machine (VM ) as per course instructions, faced a module not found error in jupyter notebook .\n",
      "The solution which worked for me(use following in jupyter notebook) :\n",
      "!pip install findspark\n",
      "import findspark\n",
      "findspark.init()\n",
      "Thereafter , import pyspark and create spark contex<<t as usual\n",
      "None of the solutions above worked for me till I ran !pip3 install pyspark instead !pip install pyspark.\n",
      "Filter based on conditions based on multiple columns\n",
      "from pyspark.sql.functions import col\n",
      "new_final.filter((new_final.a_zone==\"Murray Hill\") & (new_final.b_zone==\"Midwood\")).show()\n",
      "Krishna Anand\n",
      "\n",
      "section: Module 5: pyspark\n",
      "question: Py4JJavaError - ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`\n",
      "answer: You need to look for the Py4J file and note the version of the filename. Once you know the version, you can update the export command accordingly, this is how you check yours:\n",
      "` ls ${SPARK_HOME}/python/lib/ ` and then you add it in the export command, mine was:\n",
      "export PYTHONPATH=”${SPARK_HOME}/python/lib/Py4J-0.10.9.5-src.zip:${PYTHONPATH}”\n",
      "Make sure that the version under `${SPARK_HOME}/python/lib/` matches the filename of py4j or you will encounter `ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`.\n",
      "For instance, if the file under `${SPARK_HOME}/python/lib/` was `py4j-0.10.9.3-src.zip`.\n",
      "Then the export PYTHONPATH statement above should be changed to `export PYTHONPATH=\"${SPARK_HOME}/python/lib/py4j-0.10.9.3-src.zip:$PYTHONPATH\"` appropriately.\n",
      "Additionally, you can check for the version of ‘py4j’ of the spark you’re using from here and update as mentioned above.\n",
      "~ Abhijit Chakraborty: Sometimes, even with adding the correct version of py4j might not solve the problem. Simply run pip install py4j and problem should be resolved.\n",
      "\n",
      "section: Module 4: analytics engineering with dbt\n",
      "question: DBT - Error: No module named 'pytz' while setting up dbt with docker\n",
      "answer: Following dbt with BigQuery on Docker readme.md, after `docker-compose build` and `docker-compose run dbt-bq-dtc init`, encountered error `ModuleNotFoundError: No module named 'pytz'`\n",
      "Solution:\n",
      "Add `RUN python -m pip install --no-cache pytz` in the Dockerfile under `FROM --platform=$build_for python:3.9.9-slim-bullseye as base`\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Postgres - ModuleNotFoundError: No module named 'psycopg2'\n",
      "answer: Issue:\n",
      "e…\n",
      "Solution:\n",
      "pip install psycopg2-binary\n",
      "If you already have it, you might need to update it:\n",
      "pip install psycopg2-binary --upgrade\n",
      "Other methods, if the above fails:\n",
      "if you are getting the “ ModuleNotFoundError: No module named 'psycopg2' “ error even after the above installation, then try updating conda using the command conda update -n base -c defaults conda. Or if you are using pip, then try updating it before installing the psycopg packages i.e\n",
      "First uninstall the psycopg package\n",
      "Then update conda or pip\n",
      "Then install psycopg again using pip.\n",
      "if you are still facing error with r pcycopg2 and showing pg_config not found then you will have to install postgresql. in MAC it is brew install postgresql\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Python - SQLALchemy - TypeError 'module' object is not callable\n",
      "answer: create_engine('postgresql://root:root@localhost:5432/ny_taxi')  I get the error \"TypeError: 'module' object is not callable\"\n",
      "Solution:\n",
      "conn_string = \"postgresql+psycopg://root:root@localhost:5432/ny_taxi\"\n",
      "engine = create_engine(conn_string)\n",
      "\n",
      "section: Module 6: streaming with kafka\n",
      "question: Module “kafka” not found when trying to run producer.py\n",
      "answer: Solution from Alexey: create a virtual environment and run requirements.txt and the python files in that environment.\n",
      "To create a virtual env and install packages (run only once)\n",
      "python -m venv env\n",
      "source env/bin/activate\n",
      "pip install -r ../requirements.txt\n",
      "To activate it (you'll need to run it every time you need the virtual env):\n",
      "source env/bin/activate\n",
      "To deactivate it:\n",
      "deactivate\n",
      "This works on MacOS, Linux and Windows - but for Windows the path is slightly different (it's env/Scripts/activate)\n",
      "Also the virtual environment should be created only to run the python file. Docker images should first all be up and running.\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Python - SQLAlchemy - ModuleNotFoundError: No module named 'psycopg2'.\n",
      "answer: Error raised during the jupyter notebook’s cell execution:\n",
      "engine = create_engine('postgresql://root:root@localhost:5432/ny_taxi').\n",
      "Solution: Need to install Python module “psycopg2”. Can be installed by Conda or pip.\n",
      "</CONTEXT>\n",
      "\n",
      "<PREVIOUS_ACTIONS>\n",
      "{\"action\": \"SEARCH\", \"reasoning\": \"To provide a comprehensive answer about success in module 1, I need to gather detailed guidelines or tips that relate specifically to that module from the FAQ database.\", \"keywords\": [\"module 1 success tips\", \"how to succeed in module 1\", \"module 1 requirements\"]}\n",
      "</PREVIOUS_ACTIONS>\n",
      "{\n",
      "  \"action\": \"SEARCH\",\n",
      "  \"reasoning\": \"There might be additional insights or tips in the FAQ database regarding the requirements or general advice for success in Module 1 that weren't covered in the previous search. I will look for more specific guidance related to Module 1: Docker and Terraform.\",\n",
      "  \"keywords\": [\n",
      "    \"Module 1 study tips\",\n",
      "    \"best practices for Module 1\",\n",
      "    \"success strategies for Docker and Terraform\"\n",
      "  ]\n",
      "}\n",
      "\n",
      "ITERATION #2...\n",
      "You're a course teaching assistant.\n",
      "\n",
      "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
      "\n",
      "The CONTEXT is build with the documents from our FAQ database.\n",
      "SEARCH_QUERIES contains the queries that were used to retrieve the documents\n",
      "from FAQ to and add them to the context.\n",
      "PREVIOUS_ACTIONS contains the actions you already performed.\n",
      "\n",
      "At the beginning the CONTEXT is empty.\n",
      "\n",
      "You can perform the following actions:\n",
      "\n",
      "- Search in the FAQ database to get more data for the CONTEXT\n",
      "- Answer the question using the CONTEXT\n",
      "- Answer the question using your own knowledge\n",
      "\n",
      "For the SEARCH action, build search requests based on the CONTEXT and the QUESTION.\n",
      "Carefully analyze the CONTEXT and generate the requests to deeply explore the topic. \n",
      "\n",
      "Don't use search queries used at the previous iterations.\n",
      "\n",
      "Don't repeat previously performed actions.\n",
      "\n",
      "Don't perform more than 3 iterations for a given student question.\n",
      "The current iteration number: 2. If we exceed the allowed number \n",
      "of iterations, give the best possible answer with the provided information.\n",
      "\n",
      "Output templates:\n",
      "\n",
      "If you want to perform search, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"SEARCH\",\n",
      "\"reasoning\": \"<add your reasoning here>\",\n",
      "\"keywords\": [\"search query 1\", \"search query 2\", ...]\n",
      "}\n",
      "\n",
      "If you can answer the QUESTION using CONTEXT, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER_CONTEXT\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"CONTEXT\"\n",
      "}\n",
      "\n",
      "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n",
      "\n",
      "<QUESTION>\n",
      "what do I need to do to be successful at module 1?\n",
      "</QUESTION>\n",
      "\n",
      "<SEARCH_QUERIES>\n",
      "best practices for Module 1\n",
      "module 1 success tips\n",
      "module 1 requirements\n",
      "how to succeed in module 1\n",
      "Module 1 study tips\n",
      "success strategies for Docker and Terraform\n",
      "</SEARCH_QUERIES>\n",
      "\n",
      "<CONTEXT> \n",
      "section: Module 5: pyspark\n",
      "question: Module Not Found Error in Jupyter Notebook .\n",
      "answer: Even after installing pyspark correctly on linux machine (VM ) as per course instructions, faced a module not found error in jupyter notebook .\n",
      "The solution which worked for me(use following in jupyter notebook) :\n",
      "!pip install findspark\n",
      "import findspark\n",
      "findspark.init()\n",
      "Thereafter , import pyspark and create spark contex<<t as usual\n",
      "None of the solutions above worked for me till I ran !pip3 install pyspark instead !pip install pyspark.\n",
      "Filter based on conditions based on multiple columns\n",
      "from pyspark.sql.functions import col\n",
      "new_final.filter((new_final.a_zone==\"Murray Hill\") & (new_final.b_zone==\"Midwood\")).show()\n",
      "Krishna Anand\n",
      "\n",
      "section: Module 5: pyspark\n",
      "question: Py4JJavaError - ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`\n",
      "answer: You need to look for the Py4J file and note the version of the filename. Once you know the version, you can update the export command accordingly, this is how you check yours:\n",
      "` ls ${SPARK_HOME}/python/lib/ ` and then you add it in the export command, mine was:\n",
      "export PYTHONPATH=”${SPARK_HOME}/python/lib/Py4J-0.10.9.5-src.zip:${PYTHONPATH}”\n",
      "Make sure that the version under `${SPARK_HOME}/python/lib/` matches the filename of py4j or you will encounter `ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`.\n",
      "For instance, if the file under `${SPARK_HOME}/python/lib/` was `py4j-0.10.9.3-src.zip`.\n",
      "Then the export PYTHONPATH statement above should be changed to `export PYTHONPATH=\"${SPARK_HOME}/python/lib/py4j-0.10.9.3-src.zip:$PYTHONPATH\"` appropriately.\n",
      "Additionally, you can check for the version of ‘py4j’ of the spark you’re using from here and update as mentioned above.\n",
      "~ Abhijit Chakraborty: Sometimes, even with adding the correct version of py4j might not solve the problem. Simply run pip install py4j and problem should be resolved.\n",
      "\n",
      "section: Module 4: analytics engineering with dbt\n",
      "question: DBT - Error: No module named 'pytz' while setting up dbt with docker\n",
      "answer: Following dbt with BigQuery on Docker readme.md, after `docker-compose build` and `docker-compose run dbt-bq-dtc init`, encountered error `ModuleNotFoundError: No module named 'pytz'`\n",
      "Solution:\n",
      "Add `RUN python -m pip install --no-cache pytz` in the Dockerfile under `FROM --platform=$build_for python:3.9.9-slim-bullseye as base`\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Postgres - ModuleNotFoundError: No module named 'psycopg2'\n",
      "answer: Issue:\n",
      "e…\n",
      "Solution:\n",
      "pip install psycopg2-binary\n",
      "If you already have it, you might need to update it:\n",
      "pip install psycopg2-binary --upgrade\n",
      "Other methods, if the above fails:\n",
      "if you are getting the “ ModuleNotFoundError: No module named 'psycopg2' “ error even after the above installation, then try updating conda using the command conda update -n base -c defaults conda. Or if you are using pip, then try updating it before installing the psycopg packages i.e\n",
      "First uninstall the psycopg package\n",
      "Then update conda or pip\n",
      "Then install psycopg again using pip.\n",
      "if you are still facing error with r pcycopg2 and showing pg_config not found then you will have to install postgresql. in MAC it is brew install postgresql\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Python - SQLALchemy - TypeError 'module' object is not callable\n",
      "answer: create_engine('postgresql://root:root@localhost:5432/ny_taxi')  I get the error \"TypeError: 'module' object is not callable\"\n",
      "Solution:\n",
      "conn_string = \"postgresql+psycopg://root:root@localhost:5432/ny_taxi\"\n",
      "engine = create_engine(conn_string)\n",
      "\n",
      "section: Module 6: streaming with kafka\n",
      "question: Module “kafka” not found when trying to run producer.py\n",
      "answer: Solution from Alexey: create a virtual environment and run requirements.txt and the python files in that environment.\n",
      "To create a virtual env and install packages (run only once)\n",
      "python -m venv env\n",
      "source env/bin/activate\n",
      "pip install -r ../requirements.txt\n",
      "To activate it (you'll need to run it every time you need the virtual env):\n",
      "source env/bin/activate\n",
      "To deactivate it:\n",
      "deactivate\n",
      "This works on MacOS, Linux and Windows - but for Windows the path is slightly different (it's env/Scripts/activate)\n",
      "Also the virtual environment should be created only to run the python file. Docker images should first all be up and running.\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Python - SQLAlchemy - ModuleNotFoundError: No module named 'psycopg2'.\n",
      "answer: Error raised during the jupyter notebook’s cell execution:\n",
      "engine = create_engine('postgresql://root:root@localhost:5432/ny_taxi').\n",
      "Solution: Need to install Python module “psycopg2”. Can be installed by Conda or pip.\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Docker - cs to store all code in your default Linux distro to get the best out of file system performance (since Docker runs on WSL2 backend by default for Windows 10 Home / Windows 11 Home users).\n",
      "answer: More info in the Docker Docs on Best Practises\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Terraform - Error: Failed to query available provider packages │ Could not retrieve the list of available versions for provider hashicorp/google: could not query │ provider registry for registry.terrafogorm.io/hashicorp/google: the request failed after 2 attempts, │ please try again later\n",
      "answer: It is an internet connectivity error, terraform is somehow not able to access the online registry. Check your VPN/Firewall settings (or just clear cookies or restart your network). Try terraform init again after this, it should work.\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Terraform - Error acquiring the state lock\n",
      "answer: https://github.com/hashicorp/terraform/issues/14513\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Terraform - Where can I find the Terraform 1.1.3 Linux (AMD 64)?\n",
      "answer: Here: https://releases.hashicorp.com/terraform/1.1.3/terraform_1.1.3_linux_amd64.zip\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Terraform - Terraform initialized in an empty directory! The directory has no Terraform configuration files. You may begin working with Terraform immediately by creating Terraform configuration files.g\n",
      "answer: You get this error because I run the command terraform init outside the working directory, and this is wrong.You need first to navigate to the working directory that contains terraform configuration files, and and then run the command.\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Terraform - Error 400 Bad Request.  Invalid JWT Token  on WSL.\n",
      "answer: When running\n",
      "terraform apply\n",
      "on wsl2 I've got this error:\n",
      "│ Error: Post \"https://storage.googleapis.com/storage/v1/b?alt=json&prettyPrint=false&project=<your-project-id>\": oauth2: cannot fetch token: 400 Bad Request\n",
      "│ Response: {\"error\":\"invalid_grant\",\"error_description\":\"Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.\"}\n",
      "IT happens because there may be time desync on your machine which affects computing JWT\n",
      "To fix this, run the command\n",
      "sudo hwclock -s\n",
      "which fixes your system time.\n",
      "Reference\n",
      "</CONTEXT>\n",
      "\n",
      "<PREVIOUS_ACTIONS>\n",
      "{\"action\": \"SEARCH\", \"reasoning\": \"To provide a comprehensive answer about success in module 1, I need to gather detailed guidelines or tips that relate specifically to that module from the FAQ database.\", \"keywords\": [\"module 1 success tips\", \"how to succeed in module 1\", \"module 1 requirements\"]}\n",
      "{\"action\": \"SEARCH\", \"reasoning\": \"There might be additional insights or tips in the FAQ database regarding the requirements or general advice for success in Module 1 that weren't covered in the previous search. I will look for more specific guidance related to Module 1: Docker and Terraform.\", \"keywords\": [\"Module 1 study tips\", \"best practices for Module 1\", \"success strategies for Docker and Terraform\"]}\n",
      "</PREVIOUS_ACTIONS>\n",
      "{\n",
      "  \"action\": \"SEARCH\",\n",
      "  \"reasoning\": \"To ensure I provide the most relevant and effective strategies for success in Module 1: Docker and Terraform, I will search for insights specifically regarding best practices and strategies for using Docker and Terraform effectively, since they are the main topics of this module.\",\n",
      "  \"keywords\": [\n",
      "    \"best practices for Docker\",\n",
      "    \"success strategies for Terraform\",\n",
      "    \"effective use of Docker and Terraform\"\n",
      "  ]\n",
      "}\n",
      "\n",
      "ITERATION #3...\n",
      "You're a course teaching assistant.\n",
      "\n",
      "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
      "\n",
      "The CONTEXT is build with the documents from our FAQ database.\n",
      "SEARCH_QUERIES contains the queries that were used to retrieve the documents\n",
      "from FAQ to and add them to the context.\n",
      "PREVIOUS_ACTIONS contains the actions you already performed.\n",
      "\n",
      "At the beginning the CONTEXT is empty.\n",
      "\n",
      "You can perform the following actions:\n",
      "\n",
      "- Search in the FAQ database to get more data for the CONTEXT\n",
      "- Answer the question using the CONTEXT\n",
      "- Answer the question using your own knowledge\n",
      "\n",
      "For the SEARCH action, build search requests based on the CONTEXT and the QUESTION.\n",
      "Carefully analyze the CONTEXT and generate the requests to deeply explore the topic. \n",
      "\n",
      "Don't use search queries used at the previous iterations.\n",
      "\n",
      "Don't repeat previously performed actions.\n",
      "\n",
      "Don't perform more than 3 iterations for a given student question.\n",
      "The current iteration number: 3. If we exceed the allowed number \n",
      "of iterations, give the best possible answer with the provided information.\n",
      "\n",
      "Output templates:\n",
      "\n",
      "If you want to perform search, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"SEARCH\",\n",
      "\"reasoning\": \"<add your reasoning here>\",\n",
      "\"keywords\": [\"search query 1\", \"search query 2\", ...]\n",
      "}\n",
      "\n",
      "If you can answer the QUESTION using CONTEXT, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER_CONTEXT\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"CONTEXT\"\n",
      "}\n",
      "\n",
      "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n",
      "\n",
      "<QUESTION>\n",
      "what do I need to do to be successful at module 1?\n",
      "</QUESTION>\n",
      "\n",
      "<SEARCH_QUERIES>\n",
      "best practices for Module 1\n",
      "module 1 success tips\n",
      "best practices for Docker\n",
      "module 1 requirements\n",
      "how to succeed in module 1\n",
      "success strategies for Terraform\n",
      "effective use of Docker and Terraform\n",
      "Module 1 study tips\n",
      "success strategies for Docker and Terraform\n",
      "</SEARCH_QUERIES>\n",
      "\n",
      "<CONTEXT> \n",
      "section: Module 5: pyspark\n",
      "question: Module Not Found Error in Jupyter Notebook .\n",
      "answer: Even after installing pyspark correctly on linux machine (VM ) as per course instructions, faced a module not found error in jupyter notebook .\n",
      "The solution which worked for me(use following in jupyter notebook) :\n",
      "!pip install findspark\n",
      "import findspark\n",
      "findspark.init()\n",
      "Thereafter , import pyspark and create spark contex<<t as usual\n",
      "None of the solutions above worked for me till I ran !pip3 install pyspark instead !pip install pyspark.\n",
      "Filter based on conditions based on multiple columns\n",
      "from pyspark.sql.functions import col\n",
      "new_final.filter((new_final.a_zone==\"Murray Hill\") & (new_final.b_zone==\"Midwood\")).show()\n",
      "Krishna Anand\n",
      "\n",
      "section: Module 5: pyspark\n",
      "question: Py4JJavaError - ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`\n",
      "answer: You need to look for the Py4J file and note the version of the filename. Once you know the version, you can update the export command accordingly, this is how you check yours:\n",
      "` ls ${SPARK_HOME}/python/lib/ ` and then you add it in the export command, mine was:\n",
      "export PYTHONPATH=”${SPARK_HOME}/python/lib/Py4J-0.10.9.5-src.zip:${PYTHONPATH}”\n",
      "Make sure that the version under `${SPARK_HOME}/python/lib/` matches the filename of py4j or you will encounter `ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`.\n",
      "For instance, if the file under `${SPARK_HOME}/python/lib/` was `py4j-0.10.9.3-src.zip`.\n",
      "Then the export PYTHONPATH statement above should be changed to `export PYTHONPATH=\"${SPARK_HOME}/python/lib/py4j-0.10.9.3-src.zip:$PYTHONPATH\"` appropriately.\n",
      "Additionally, you can check for the version of ‘py4j’ of the spark you’re using from here and update as mentioned above.\n",
      "~ Abhijit Chakraborty: Sometimes, even with adding the correct version of py4j might not solve the problem. Simply run pip install py4j and problem should be resolved.\n",
      "\n",
      "section: Module 4: analytics engineering with dbt\n",
      "question: DBT - Error: No module named 'pytz' while setting up dbt with docker\n",
      "answer: Following dbt with BigQuery on Docker readme.md, after `docker-compose build` and `docker-compose run dbt-bq-dtc init`, encountered error `ModuleNotFoundError: No module named 'pytz'`\n",
      "Solution:\n",
      "Add `RUN python -m pip install --no-cache pytz` in the Dockerfile under `FROM --platform=$build_for python:3.9.9-slim-bullseye as base`\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Postgres - ModuleNotFoundError: No module named 'psycopg2'\n",
      "answer: Issue:\n",
      "e…\n",
      "Solution:\n",
      "pip install psycopg2-binary\n",
      "If you already have it, you might need to update it:\n",
      "pip install psycopg2-binary --upgrade\n",
      "Other methods, if the above fails:\n",
      "if you are getting the “ ModuleNotFoundError: No module named 'psycopg2' “ error even after the above installation, then try updating conda using the command conda update -n base -c defaults conda. Or if you are using pip, then try updating it before installing the psycopg packages i.e\n",
      "First uninstall the psycopg package\n",
      "Then update conda or pip\n",
      "Then install psycopg again using pip.\n",
      "if you are still facing error with r pcycopg2 and showing pg_config not found then you will have to install postgresql. in MAC it is brew install postgresql\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Python - SQLALchemy - TypeError 'module' object is not callable\n",
      "answer: create_engine('postgresql://root:root@localhost:5432/ny_taxi')  I get the error \"TypeError: 'module' object is not callable\"\n",
      "Solution:\n",
      "conn_string = \"postgresql+psycopg://root:root@localhost:5432/ny_taxi\"\n",
      "engine = create_engine(conn_string)\n",
      "\n",
      "section: Module 6: streaming with kafka\n",
      "question: Module “kafka” not found when trying to run producer.py\n",
      "answer: Solution from Alexey: create a virtual environment and run requirements.txt and the python files in that environment.\n",
      "To create a virtual env and install packages (run only once)\n",
      "python -m venv env\n",
      "source env/bin/activate\n",
      "pip install -r ../requirements.txt\n",
      "To activate it (you'll need to run it every time you need the virtual env):\n",
      "source env/bin/activate\n",
      "To deactivate it:\n",
      "deactivate\n",
      "This works on MacOS, Linux and Windows - but for Windows the path is slightly different (it's env/Scripts/activate)\n",
      "Also the virtual environment should be created only to run the python file. Docker images should first all be up and running.\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Python - SQLAlchemy - ModuleNotFoundError: No module named 'psycopg2'.\n",
      "answer: Error raised during the jupyter notebook’s cell execution:\n",
      "engine = create_engine('postgresql://root:root@localhost:5432/ny_taxi').\n",
      "Solution: Need to install Python module “psycopg2”. Can be installed by Conda or pip.\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Docker - cs to store all code in your default Linux distro to get the best out of file system performance (since Docker runs on WSL2 backend by default for Windows 10 Home / Windows 11 Home users).\n",
      "answer: More info in the Docker Docs on Best Practises\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Terraform - Error: Failed to query available provider packages │ Could not retrieve the list of available versions for provider hashicorp/google: could not query │ provider registry for registry.terrafogorm.io/hashicorp/google: the request failed after 2 attempts, │ please try again later\n",
      "answer: It is an internet connectivity error, terraform is somehow not able to access the online registry. Check your VPN/Firewall settings (or just clear cookies or restart your network). Try terraform init again after this, it should work.\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Terraform - Error acquiring the state lock\n",
      "answer: https://github.com/hashicorp/terraform/issues/14513\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Terraform - Where can I find the Terraform 1.1.3 Linux (AMD 64)?\n",
      "answer: Here: https://releases.hashicorp.com/terraform/1.1.3/terraform_1.1.3_linux_amd64.zip\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Terraform - Terraform initialized in an empty directory! The directory has no Terraform configuration files. You may begin working with Terraform immediately by creating Terraform configuration files.g\n",
      "answer: You get this error because I run the command terraform init outside the working directory, and this is wrong.You need first to navigate to the working directory that contains terraform configuration files, and and then run the command.\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Terraform - Error 400 Bad Request.  Invalid JWT Token  on WSL.\n",
      "answer: When running\n",
      "terraform apply\n",
      "on wsl2 I've got this error:\n",
      "│ Error: Post \"https://storage.googleapis.com/storage/v1/b?alt=json&prettyPrint=false&project=<your-project-id>\": oauth2: cannot fetch token: 400 Bad Request\n",
      "│ Response: {\"error\":\"invalid_grant\",\"error_description\":\"Invalid JWT: Token must be a short-lived token (60 minutes) and in a reasonable timeframe. Check your iat and exp values in the JWT claim.\"}\n",
      "IT happens because there may be time desync on your machine which affects computing JWT\n",
      "To fix this, run the command\n",
      "sudo hwclock -s\n",
      "which fixes your system time.\n",
      "Reference\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Docker-Compose - Hostname does not resolve\n",
      "answer: It returns --> Error response from daemon: network 66ae65944d643fdebbc89bd0329f1409dec2c9e12248052f5f4c4be7d1bdc6a3 not found\n",
      "Try:\n",
      "docker ps -a to see all the stopped & running containers\n",
      "d to nuke all the containers\n",
      "Try: docker-compose up -d again ports\n",
      "On localhost:8080 server → Unable to connect to server: could not translate host name 'pg-database' to address: Name does not resolve\n",
      "Try: new host name, best without “ - ” e.g. pgdatabase\n",
      "And on docker-compose.yml, should specify docker network & specify the same network in both  containers\n",
      "services:\n",
      "pgdatabase:\n",
      "image: postgres:13\n",
      "environment:\n",
      "- POSTGRES_USER=root\n",
      "- POSTGRES_PASSWORD=root\n",
      "- POSTGRES_DB=ny_taxi\n",
      "volumes:\n",
      "- \"./ny_taxi_postgres_data:/var/lib/postgresql/data:rw\"\n",
      "ports:\n",
      "- \"5431:5432\"\n",
      "networks:\n",
      "- pg-network\n",
      "pgadmin:\n",
      "image: dpage/pgadmin4\n",
      "environment:\n",
      "- PGADMIN_DEFAULT_EMAIL=admin@admin.com\n",
      "- PGADMIN_DEFAULT_PASSWORD=root\n",
      "ports:\n",
      "- \"8080:80\"\n",
      "networks:\n",
      "- pg-network\n",
      "networks:\n",
      "pg-network:\n",
      "name: pg-network\n",
      "\n",
      "section: Module 2: Workflow Orchestration\n",
      "question: Docker - 2.2.2 Configure Mage\n",
      "answer: Issue : Docker containers exit instantly with code 132, upon docker compose up\n",
      "Mage documentation has it listing the cause as \"older architecture\" .\n",
      "This might be a hardware issue, so unless you have another computer, you can't solve it without purchasing a new one, so the next best solution is a VM.\n",
      "This is from a student running on a VirtualBox VM, Ubuntu 22.04.3 LTS, Docker version 25.0.2. So not having the context on how the vbox was spin up with (CPU, RAM, network, etc), it’s really inconclusive at this time.\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Docker - can’t delete local folder that mounted to docker volume\n",
      "answer: When I runned command to create postgre in docker container it created folder on my local machine to mount it to volume inside container. It has write and read protection and owned by user 999, so I could not delete it by simply drag to trash.  My obsidian could not started due to access error, so I had to change placement of this folder and delete old folder by this command:\n",
      "sudo rm -r -f docker_test/\n",
      "- where `rm` - remove, `-r` - recursively, `-f` - force, `docker_test/` - folder.\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Docker - Cannot connect to Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running?\n",
      "answer: Make sure you're able to start the Docker daemon, and check the issue immediately down below:\n",
      "And don’t forget to update the wsl in powershell the  command is wsl –update\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Terraform - Install for WSL\n",
      "answer: https://techcommunity.microsoft.com/t5/azure-developer-community-blog/configuring-terraform-on-windows-10-linux-sub-system/ba-p/393845\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Terraform - Error:Post \"https://storage.googleapis.com/storage/v1/b?alt=json&prettyPrint=false&project=coherent-ascent-379901\": oauth2: cannot fetch token: Post \"https://oauth2.googleapis.com/token\": dial tcp 172.217.163.42:443: i/o timeout\n",
      "answer: The issue was with the network. Google is not accessible in my country, I am using a VPN. And The terminal program does not automatically follow the system proxy and requires separate proxy configuration settings.I opened a Enhanced Mode in Clash, which is a VPN app, and 'terraform apply' works! So if you encounter the same issue, you can ask help for your vpn provider.\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Terraform - Error creating Bucket: googleapi: Error 403: Permission denied to access ‘storage.buckets.create’\n",
      "answer: The error:\n",
      "Error: googleapi: Error 403: terraform-trans-campus@trans-campus-410115.iam.gserviceaccount.com does not have storage.buckets.create access to the Google Cloud project. Permission 'storage.buckets.create' denied on resource (or it may not exist)., forbidden\n",
      "The solution:\n",
      "You have to declare the project name as your Project ID, and not your Project name, available on GCP console Dashboard.\n",
      "</CONTEXT>\n",
      "\n",
      "<PREVIOUS_ACTIONS>\n",
      "{\"action\": \"SEARCH\", \"reasoning\": \"To provide a comprehensive answer about success in module 1, I need to gather detailed guidelines or tips that relate specifically to that module from the FAQ database.\", \"keywords\": [\"module 1 success tips\", \"how to succeed in module 1\", \"module 1 requirements\"]}\n",
      "{\"action\": \"SEARCH\", \"reasoning\": \"There might be additional insights or tips in the FAQ database regarding the requirements or general advice for success in Module 1 that weren't covered in the previous search. I will look for more specific guidance related to Module 1: Docker and Terraform.\", \"keywords\": [\"Module 1 study tips\", \"best practices for Module 1\", \"success strategies for Docker and Terraform\"]}\n",
      "{\"action\": \"SEARCH\", \"reasoning\": \"To ensure I provide the most relevant and effective strategies for success in Module 1: Docker and Terraform, I will search for insights specifically regarding best practices and strategies for using Docker and Terraform effectively, since they are the main topics of this module.\", \"keywords\": [\"best practices for Docker\", \"success strategies for Terraform\", \"effective use of Docker and Terraform\"]}\n",
      "</PREVIOUS_ACTIONS>\n",
      "{\n",
      "  \"action\": \"ANSWER\",\n",
      "  \"answer\": \"To be successful in Module 1: Docker and Terraform, consider the following strategies:\\n\\n1. **Understand the Tools**: Familiarize yourself with both Docker and Terraform concepts, as they are fundamental to this module. Make sure you grasp how Docker manages containerization and how Terraform is used for infrastructure as code.\\n\\n2. **Hands-On Practice**: Engage with practical exercises as much as possible. Set up Docker containers and practice writing Terraform configurations to solidify your understanding.\\n\\n3. **Follow Documentation**: Utilize the official documentation for Docker and Terraform. They provide comprehensive guides and examples that can help clarify usage.\\n\\n4. **Community Resources**: Leverage forums, community discussions, or study groups to share challenges and solutions with peers. Platforms like Stack Overflow can be particularly useful for troubleshooting specific issues.\\n\\n5. **Keep Environment Updated**: Make sure your Docker and Terraform installations are up to date to avoid any compatibility issues. Regularly check for the latest versions and environment setups.\\n\\n6. **Network Configuration**: Be mindful of networking settings when working with Docker, particularly if running on WSL or different operating systems. Ensure that container ports are correctly mapped and accessible.\\n\\n7. **Debugging Skills**: Develop your debugging skills to troubleshoot common issues, such as connection problems with Docker or Terraform errors. Familiarize yourself with common error messages and how to resolve them.\\n\\n8. **Project-Based Learning**: Try to build a small project that uses Docker and Terraform together. This real-world application will help reinforce your learning.\\n\\nBy focusing on these strategies, you can enhance your understanding and performance in Module 1, leading to a more successful experience.\",\n",
      "  \"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'action': 'ANSWER',\n",
       " 'answer': 'To be successful in Module 1: Docker and Terraform, consider the following strategies:\\n\\n1. **Understand the Tools**: Familiarize yourself with both Docker and Terraform concepts, as they are fundamental to this module. Make sure you grasp how Docker manages containerization and how Terraform is used for infrastructure as code.\\n\\n2. **Hands-On Practice**: Engage with practical exercises as much as possible. Set up Docker containers and practice writing Terraform configurations to solidify your understanding.\\n\\n3. **Follow Documentation**: Utilize the official documentation for Docker and Terraform. They provide comprehensive guides and examples that can help clarify usage.\\n\\n4. **Community Resources**: Leverage forums, community discussions, or study groups to share challenges and solutions with peers. Platforms like Stack Overflow can be particularly useful for troubleshooting specific issues.\\n\\n5. **Keep Environment Updated**: Make sure your Docker and Terraform installations are up to date to avoid any compatibility issues. Regularly check for the latest versions and environment setups.\\n\\n6. **Network Configuration**: Be mindful of networking settings when working with Docker, particularly if running on WSL or different operating systems. Ensure that container ports are correctly mapped and accessible.\\n\\n7. **Debugging Skills**: Develop your debugging skills to troubleshoot common issues, such as connection problems with Docker or Terraform errors. Familiarize yourself with common error messages and how to resolve them.\\n\\n8. **Project-Based Learning**: Try to build a small project that uses Docker and Terraform together. This real-world application will help reinforce your learning.\\n\\nBy focusing on these strategies, you can enhance your understanding and performance in Module 1, leading to a more successful experience.',\n",
       " 'source': 'OWN_KNOWLEDGE'}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"what do I need to do to be successful at module 1?\"\n",
    "\n",
    "agentic_search(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b804ce6",
   "metadata": {},
   "source": [
    "### Part 3: Function calling (`tool use`)\n",
    "\n",
    "Tradional Approach: We put all this logic inside our prompt. \n",
    "\n",
    "* But OpenAI and other providers provide a convienient API for adding extra functionality like `search`.\n",
    "\n",
    "* It's called `function-calling` or `tool usage`: you can define functions that the model can call, and if it decides to make a call, it returns structured output for that."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c007ae",
   "metadata": {},
   "source": [
    "For exmaple: let's take our `search` function: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56f0345c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query):\n",
    "    boost = {'question': 3.0, 'section': 0.5}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={'course': 'data-engineering-zoomcamp'},\n",
    "        boost_dict=boost,\n",
    "        num_results=5,\n",
    "        output_ids=True\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375ca2c9",
   "metadata": {},
   "source": [
    "We describe it like that: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b46ecb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_tool = {\n",
    "    \"type\": \"function\",\n",
    "    \"name\": \"search\",\n",
    "    \"description\": \"Search the FAQ database\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"query\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Search query text to look up in the course FAQ.\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"query\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac3b7338",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ResponseFunctionToolCall(arguments='{\"query\":\"how to do well in module 1\"}', call_id='call_cw8bzVd8lRuyOnZZ3c6n0PDK', name='search', type='function_call', id='fc_6874d3e6ffe08196b7b3ba35e7a7f18f062c3b20eb6abbce', status='completed')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"How do I do well in module 1?\"\n",
    "\n",
    "developer_prompt = \"\"\"\n",
    "You're a course teaching assistant. \n",
    "You're given a question from a course student and your task is to answer it. \n",
    "\"\"\".strip()\n",
    "\n",
    "tools = [search_tool]\n",
    "\n",
    "chat_messages = [\n",
    "    {\"role\": \"developer\", \"content\": developer_prompt},\n",
    "    {\"role\": \"user\", \"content\": question}\n",
    "]\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    input=chat_messages,\n",
    "    tools=tools\n",
    ")\n",
    "\n",
    "response.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2029668",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(id='resp_6874d3e633288196a7272d14b316b1d5062c3b20eb6abbce', created_at=1752486886.0, error=None, incomplete_details=None, instructions=None, metadata={}, model='gpt-4o-mini-2024-07-18', object='response', output=[ResponseFunctionToolCall(arguments='{\"query\":\"how to do well in module 1\"}', call_id='call_cw8bzVd8lRuyOnZZ3c6n0PDK', name='search', type='function_call', id='fc_6874d3e6ffe08196b7b3ba35e7a7f18f062c3b20eb6abbce', status='completed')], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[FunctionTool(name='search', parameters={'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'Search query text to look up in the course FAQ.'}}, 'required': ['query'], 'additionalProperties': False}, strict=True, type='function', description='Search the FAQ database')], top_p=1.0, background=False, max_output_tokens=None, previous_response_id=None, reasoning=Reasoning(effort=None, generate_summary=None, summary=None), service_tier='default', status='completed', text=ResponseTextConfig(format=ResponseFormatText(type='text')), truncation='disabled', usage=ResponseUsage(input_tokens=84, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=21, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=105), user=None, max_tool_calls=None, store=True, top_logprobs=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "26fd823e",
   "metadata": {},
   "outputs": [],
   "source": [
    "calls = response.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "73ca86a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "call = calls[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "838c6f1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResponseFunctionToolCall(arguments='{\"query\":\"how to do well in module 1\"}', call_id='call_cw8bzVd8lRuyOnZZ3c6n0PDK', name='search', type='function_call', id='fc_6874d3e6ffe08196b7b3ba35e7a7f18f062c3b20eb6abbce', status='completed')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7baec246",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_name = call.name "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7a6ab20d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'search'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6b5f46cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': 'how to do well in module 1'}\n"
     ]
    }
   ],
   "source": [
    "arguments = json.loads(call.arguments)\n",
    "\n",
    "print(arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "43ca93ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'function',\n",
       " 'name': 'search',\n",
       " 'description': 'Search the FAQ database',\n",
       " 'parameters': {'type': 'object',\n",
       "  'properties': {'query': {'type': 'string',\n",
       "    'description': 'Search query text to look up in the course FAQ.'}},\n",
       "  'required': ['query'],\n",
       "  'additionalProperties': False}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "globals()['search_tool']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6c038915",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = globals()[f_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bd35c214",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_results = f(**arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bae0ae88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'Even after installing pyspark correctly on linux machine (VM ) as per course instructions, faced a module not found error in jupyter notebook .\\nThe solution which worked for me(use following in jupyter notebook) :\\n!pip install findspark\\nimport findspark\\nfindspark.init()\\nThereafter , import pyspark and create spark contex<<t as usual\\nNone of the solutions above worked for me till I ran !pip3 install pyspark instead !pip install pyspark.\\nFilter based on conditions based on multiple columns\\nfrom pyspark.sql.functions import col\\nnew_final.filter((new_final.a_zone==\"Murray Hill\") & (new_final.b_zone==\"Midwood\")).show()\\nKrishna Anand',\n",
       "  'section': 'Module 5: pyspark',\n",
       "  'question': 'Module Not Found Error in Jupyter Notebook .',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  '_id': 322},\n",
       " {'text': 'You need to look for the Py4J file and note the version of the filename. Once you know the version, you can update the export command accordingly, this is how you check yours:\\n` ls ${SPARK_HOME}/python/lib/ ` and then you add it in the export command, mine was:\\nexport PYTHONPATH=”${SPARK_HOME}/python/lib/Py4J-0.10.9.5-src.zip:${PYTHONPATH}”\\nMake sure that the version under `${SPARK_HOME}/python/lib/` matches the filename of py4j or you will encounter `ModuleNotFoundError: No module named \\'py4j\\'` while executing `import pyspark`.\\nFor instance, if the file under `${SPARK_HOME}/python/lib/` was `py4j-0.10.9.3-src.zip`.\\nThen the export PYTHONPATH statement above should be changed to `export PYTHONPATH=\"${SPARK_HOME}/python/lib/py4j-0.10.9.3-src.zip:$PYTHONPATH\"` appropriately.\\nAdditionally, you can check for the version of ‘py4j’ of the spark you’re using from here and update as mentioned above.\\n~ Abhijit Chakraborty: Sometimes, even with adding the correct version of py4j might not solve the problem. Simply run pip install py4j and problem should be resolved.',\n",
       "  'section': 'Module 5: pyspark',\n",
       "  'question': \"Py4JJavaError - ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`\",\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  '_id': 323},\n",
       " {'text': \"Following dbt with BigQuery on Docker readme.md, after `docker-compose build` and `docker-compose run dbt-bq-dtc init`, encountered error `ModuleNotFoundError: No module named 'pytz'`\\nSolution:\\nAdd `RUN python -m pip install --no-cache pytz` in the Dockerfile under `FROM --platform=$build_for python:3.9.9-slim-bullseye as base`\",\n",
       "  'section': 'Module 4: analytics engineering with dbt',\n",
       "  'question': \"DBT - Error: No module named 'pytz' while setting up dbt with docker\",\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  '_id': 299},\n",
       " {'text': 'create_engine(\\'postgresql://root:root@localhost:5432/ny_taxi\\')  I get the error \"TypeError: \\'module\\' object is not callable\"\\nSolution:\\nconn_string = \"postgresql+psycopg://root:root@localhost:5432/ny_taxi\"\\nengine = create_engine(conn_string)',\n",
       "  'section': 'Module 1: Docker and Terraform',\n",
       "  'question': \"Python - SQLALchemy - TypeError 'module' object is not callable\",\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  '_id': 124},\n",
       " {'text': \"Error raised during the jupyter notebook’s cell execution:\\nengine = create_engine('postgresql://root:root@localhost:5432/ny_taxi').\\nSolution: Need to install Python module “psycopg2”. Can be installed by Conda or pip.\",\n",
       "  'section': 'Module 1: Docker and Terraform',\n",
       "  'question': \"Python - SQLAlchemy - ModuleNotFoundError: No module named 'psycopg2'.\",\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  '_id': 125}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fd546b",
   "metadata": {},
   "source": [
    "And the save both the response and the result of the function call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ce230ad9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResponseFunctionToolCall(arguments='{\"query\":\"how to do well in module 1\"}', call_id='call_cw8bzVd8lRuyOnZZ3c6n0PDK', name='search', type='function_call', id='fc_6874d3e6ffe08196b7b3ba35e7a7f18f062c3b20eb6abbce', status='completed')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7f2b8532",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_messages.append(call)\n",
    "\n",
    "chat_messages.append({\n",
    "    \"type\": \"function_call_output\",\n",
    "    \"call_id\": call.call_id,\n",
    "    \"output\": json.dumps(search_results),\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8759cd4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ResponseFunctionToolCall(arguments='{\"query\":\"how to do well in module 1\"}', call_id='call_cw8bzVd8lRuyOnZZ3c6n0PDK', name='search', type='function_call', id='fc_6874d3e6ffe08196b7b3ba35e7a7f18f062c3b20eb6abbce', status='completed'),\n",
       " {'type': 'function_call_output',\n",
       "  'call_id': 'call_cw8bzVd8lRuyOnZZ3c6n0PDK',\n",
       "  'output': '[{\"text\": \"Even after installing pyspark correctly on linux machine (VM ) as per course instructions, faced a module not found error in jupyter notebook .\\\\nThe solution which worked for me(use following in jupyter notebook) :\\\\n!pip install findspark\\\\nimport findspark\\\\nfindspark.init()\\\\nThereafter , import pyspark and create spark contex<<t as usual\\\\nNone of the solutions above worked for me till I ran !pip3 install pyspark instead !pip install pyspark.\\\\nFilter based on conditions based on multiple columns\\\\nfrom pyspark.sql.functions import col\\\\nnew_final.filter((new_final.a_zone==\\\\\"Murray Hill\\\\\") & (new_final.b_zone==\\\\\"Midwood\\\\\")).show()\\\\nKrishna Anand\", \"section\": \"Module 5: pyspark\", \"question\": \"Module Not Found Error in Jupyter Notebook .\", \"course\": \"data-engineering-zoomcamp\", \"_id\": 322}, {\"text\": \"You need to look for the Py4J file and note the version of the filename. Once you know the version, you can update the export command accordingly, this is how you check yours:\\\\n` ls ${SPARK_HOME}/python/lib/ ` and then you add it in the export command, mine was:\\\\nexport PYTHONPATH=\\\\u201d${SPARK_HOME}/python/lib/Py4J-0.10.9.5-src.zip:${PYTHONPATH}\\\\u201d\\\\nMake sure that the version under `${SPARK_HOME}/python/lib/` matches the filename of py4j or you will encounter `ModuleNotFoundError: No module named \\'py4j\\'` while executing `import pyspark`.\\\\nFor instance, if the file under `${SPARK_HOME}/python/lib/` was `py4j-0.10.9.3-src.zip`.\\\\nThen the export PYTHONPATH statement above should be changed to `export PYTHONPATH=\\\\\"${SPARK_HOME}/python/lib/py4j-0.10.9.3-src.zip:$PYTHONPATH\\\\\"` appropriately.\\\\nAdditionally, you can check for the version of \\\\u2018py4j\\\\u2019 of the spark you\\\\u2019re using from here and update as mentioned above.\\\\n~ Abhijit Chakraborty: Sometimes, even with adding the correct version of py4j might not solve the problem. Simply run pip install py4j and problem should be resolved.\", \"section\": \"Module 5: pyspark\", \"question\": \"Py4JJavaError - ModuleNotFoundError: No module named \\'py4j\\'` while executing `import pyspark`\", \"course\": \"data-engineering-zoomcamp\", \"_id\": 323}, {\"text\": \"Following dbt with BigQuery on Docker readme.md, after `docker-compose build` and `docker-compose run dbt-bq-dtc init`, encountered error `ModuleNotFoundError: No module named \\'pytz\\'`\\\\nSolution:\\\\nAdd `RUN python -m pip install --no-cache pytz` in the Dockerfile under `FROM --platform=$build_for python:3.9.9-slim-bullseye as base`\", \"section\": \"Module 4: analytics engineering with dbt\", \"question\": \"DBT - Error: No module named \\'pytz\\' while setting up dbt with docker\", \"course\": \"data-engineering-zoomcamp\", \"_id\": 299}, {\"text\": \"create_engine(\\'postgresql://root:root@localhost:5432/ny_taxi\\')  I get the error \\\\\"TypeError: \\'module\\' object is not callable\\\\\"\\\\nSolution:\\\\nconn_string = \\\\\"postgresql+psycopg://root:root@localhost:5432/ny_taxi\\\\\"\\\\nengine = create_engine(conn_string)\", \"section\": \"Module 1: Docker and Terraform\", \"question\": \"Python - SQLALchemy - TypeError \\'module\\' object is not callable\", \"course\": \"data-engineering-zoomcamp\", \"_id\": 124}, {\"text\": \"Error raised during the jupyter notebook\\\\u2019s cell execution:\\\\nengine = create_engine(\\'postgresql://root:root@localhost:5432/ny_taxi\\').\\\\nSolution: Need to install Python module \\\\u201cpsycopg2\\\\u201d. Can be installed by Conda or pip.\", \"section\": \"Module 1: Docker and Terraform\", \"question\": \"Python - SQLAlchemy - ModuleNotFoundError: No module named \\'psycopg2\\'.\", \"course\": \"data-engineering-zoomcamp\", \"_id\": 125}]'}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76200999",
   "metadata": {},
   "source": [
    "Now `chat_messages` contains both the call description (so it keeps track of history) and the results\n",
    "\n",
    "Let's make another call to the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "809da11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.responses.create(\n",
    "    model='gpt-4o-mini',\n",
    "    input=chat_messages,\n",
    "    tools=tools\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ef20d1",
   "metadata": {},
   "source": [
    "This time it should be the response (but also can be another call):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "32b98d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are some tips for doing well in Module 1 of the course \"Data Engineering Zoomcamp,\" specifically focusing on Docker and Terraform:\n",
      "\n",
      "1. **Understand Basic Concepts**: Make sure you have a solid grasp of Docker and Terraform. Review any introductory materials provided in the course to help you get started.\n",
      "\n",
      "2. **Environment Setup**:\n",
      "   - Be diligent about setting up your environment according to the instructions. This often includes installing the necessary software, such as Docker, and ensuring proper configuration.\n",
      "\n",
      "3. **Common Errors**:\n",
      "   - If you encounter errors related to SQLAlchemy (e.g., `TypeError: 'module' object is not callable`), ensure your connection string is formatted correctly.\n",
      "   - For issues like `ModuleNotFoundError: No module named 'psycopg2'`, you'll need to install the `psycopg2` module using `pip` or `conda`.\n",
      "\n",
      "4. **Utilize Resources**: Check the course materials, FAQs, or community forums for solutions to common problems. For instance, searching for specific error messages can yield helpful guidance and troubleshooting tips.\n",
      "\n",
      "5. **Practice Regularly**: Hands-on practice is crucial. Regularly work on your assignments and setups to reinforce your learning.\n",
      "\n",
      "6. **Engage with the Community**: If you run into challenges, consider asking questions in forums or study groups. Your peers may have faced similar issues and can provide insights.\n",
      "\n",
      "By focusing on these aspects, you can enhance your understanding and performance in Module 1. If you have more specific questions or need further assistance, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "r = response.output[0]\n",
    "print(r.content[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70941bb6",
   "metadata": {},
   "source": [
    "#### Making multiple calls\n",
    "\n",
    "What if we want to make multiple calls? Change the developer prompt a little:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7294bc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Added a new instruction\n",
    "developer_prompt = \"\"\"\n",
    "You're a course teaching assistant. \n",
    "You're given a question from a course student and your task is to answer it.\n",
    "If you look up something in FAQ, convert the student question into multiple queries. \n",
    "\"\"\".strip()\n",
    "\n",
    "chat_messages = [\n",
    "    {\"role\": \"developer\", \"content\": developer_prompt},\n",
    "    {\"role\": \"user\", \"content\": question}\n",
    "]\n",
    "\n",
    "response = client.responses.create(\n",
    "    model='gpt-4o-mini',\n",
    "    input=chat_messages,\n",
    "    tools=tools\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fee51c63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ResponseFunctionToolCall(arguments='{\"query\":\"How to do well in module 1?\"}', call_id='call_iRCtlo9TqDLxUgQiiXMHAcFv', name='search', type='function_call', id='fc_6874e58faeac8194a066fb11a66044480533b6d072e9dbe6', status='completed'),\n",
       " ResponseFunctionToolCall(arguments='{\"query\":\"tips for succeeding in module 1\"}', call_id='call_GoYK0Gc20wUdsYzMaqNNNrfD', name='search', type='function_call', id='fc_6874e590195c8194830641a98fcbf9b20533b6d072e9dbe6', status='completed'),\n",
       " ResponseFunctionToolCall(arguments='{\"query\":\"module 1 best practices\"}', call_id='call_CFKMgh3vBYeopf7oHz29BiH4', name='search', type='function_call', id='fc_6874e5907b14819495231206fa506d990533b6d072e9dbe6', status='completed')]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.output "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a1a051",
   "metadata": {},
   "source": [
    "This time let's organize our code a little: \n",
    "\n",
    "First, create a function: `do_call`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "68a2b1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_call(tool_call_response):\n",
    "    function_name = tool_call_response.name \n",
    "    arguments = json.loads(tool_call_response.arguments)\n",
    "\n",
    "    f = globals()[function_name]\n",
    "    search_results = f(**arguments)\n",
    "\n",
    "    return {\n",
    "        \"type\": \"function_call_output\",\n",
    "        \"call_id\": tool_call_response.call_id,\n",
    "        \"output\": json.dumps(search_results, indent=2),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fdeb9e7",
   "metadata": {},
   "source": [
    "Now Iterate over responses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "03bd4aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "function_call\n",
      "function_call\n",
      "function_call\n"
     ]
    }
   ],
   "source": [
    "# first iteration\n",
    "for entry in response.output:\n",
    "    chat_messages.append(entry)\n",
    "    print(entry.type)\n",
    "\n",
    "    if entry.type == \"function_call\":\n",
    "        result = do_call(entry)\n",
    "        chat_messages.append(result)\n",
    "\n",
    "    elif entry.type == \"message\":\n",
    "        print(entry.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c37e8d1",
   "metadata": {},
   "source": [
    "First call will probably be function call, so let's do another one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72875dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "message\n",
      "\n",
      "To do well in **Module 1**, here are some specific tips and best practices:\n",
      "\n",
      "1. **Understand Docker and Terraform**:\n",
      "   - Familiarize yourself with the fundamental concepts of Docker and Terraform, as they are the primary tools used in this module. Refer to the Docker documentation for best practices (such as storing code in your Linux distro for better performance).\n",
      "\n",
      "2. **Environment Setup**:\n",
      "   - Ensure that you have properly set up your environment according to course instructions. If you encounter errors related to modules (like `psycopg2`), the solution often involves installing the necessary Python packages. You can install `psycopg2` with:\n",
      "     ```bash\n",
      "     pip install psycopg2-binary\n",
      "     ```\n",
      "\n",
      "3. **Troubleshooting Common Errors**:\n",
      "   - If you face errors like `ModuleNotFoundError`, check that all necessary libraries are installed. If the library is already installed, consider upgrading it:\n",
      "     ```bash\n",
      "     pip install psycopg2-binary --upgrade\n",
      "     ```\n",
      "   - When using SQLAlchemy, make sure your connection string is correctly formatted to prevent errors like `TypeError: 'module' object is not callable`. Use:\n",
      "     ```python\n",
      "     conn_string = \"postgresql+psycopg://root:root@localhost:5432/ny_taxi\"\n",
      "     engine = create_engine(conn_string)\n",
      "     ```\n",
      "\n",
      "4. **Hands-on Practice**:\n",
      "   - Engage in hands-on exercises to reinforce your understanding of Docker and Terraform. Building and running containers will provide practical experience.\n",
      "\n",
      "5. **Seek Help**:\n",
      "   - If you encounter issues, utilize course forums or discussion groups to seek assistance from peers or instructors.\n",
      "\n",
      "By following these guidelines, you should improve your performance in Module 1 significantly. Good luck!\n"
     ]
    }
   ],
   "source": [
    "# 2nd iteration, after getting all context needed for the generation part\n",
    "response = client.responses.create(\n",
    "    model='gpt-4o-mini',\n",
    "    input=chat_messages,\n",
    "    tools=tools\n",
    ")\n",
    "\n",
    "for entry in response.output:\n",
    "    chat_messages.append(entry)\n",
    "    print(entry.type)\n",
    "    print()\n",
    "\n",
    "    if entry.type == 'function_call':      \n",
    "        result = do_call(entry)\n",
    "        chat_messages.append(result)\n",
    "    elif entry.type == 'message':\n",
    "        print(entry.content[0].text) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66660b45",
   "metadata": {},
   "source": [
    "### putting Everything Together:\n",
    "\n",
    "\n",
    "Let's make two loops: \n",
    "\n",
    "1. First is the main Q&A loop - ask question, get back the answer.\n",
    "2. Second is the request loop - send requests until there's a message reply from the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4a85ed61",
   "metadata": {},
   "outputs": [],
   "source": [
    "developer_prompt = \"\"\"\n",
    "You're a course teaching assistant. \n",
    "You're given a question from a course student and your task is to answer it.\n",
    "\n",
    "Use FAQ if your own knowledge is not sufficient to answer the question.\n",
    "When using FAQ, perform deep topic exploration: make one request to FAQ,\n",
    "and then based on the results, make more requests.\n",
    "\n",
    "At the end of each response, ask the user a follow up question based on your answer.\n",
    "\"\"\".strip()\n",
    "\n",
    "chat_messages = [\n",
    "    {\"role\": \"developer\", \"content\": developer_prompt},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16badb2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "function_call: ResponseFunctionToolCall(arguments='{\"query\":\"how to do well in module 1\"}', call_id='call_cWkzXu8M7jE2v9iqaftoevcL', name='search', type='function_call', id='fc_6874e759aea08197a2aa510d9b5001e40b0b1d4ba72eceb0', status='completed')\n",
      "\n",
      "function_call: ResponseFunctionToolCall(arguments='{\"query\":\"tips for success in module 1 Docker and Terraform\"}', call_id='call_ePH51aUbWJQ3mtGzATW7WFli', name='search', type='function_call', id='fc_6874e75b0ea881978f09bbd0080f18450b0b1d4ba72eceb0', status='completed')\n",
      "\n",
      "To do well in Module 1: Docker and Terraform, here are some key strategies and tips:\n",
      "\n",
      "1. **Understand the Concepts**: Make sure you grasp the fundamental concepts of both Docker and Terraform. These tools are essential for creating and managing infrastructure, so a solid understanding will help you in practical applications.\n",
      "\n",
      "2. **Follow Along with Tutorials**: Engage with any provided tutorials or videos. Since this module covers Docker and Terraform, try to replicate the examples in your own environment.\n",
      "\n",
      "3. **Hands-on Practice**: Set up a small project using Docker containers and Terraform configurations. Practical experience will deepen your learning.\n",
      "\n",
      "4. **Read Documentation**: Familiarize yourself with the official documentation for both tools. This can provide insight into best practices and advanced features.\n",
      "\n",
      "5. **Troubleshooting**: Learn how to troubleshoot common issues, such as those related to permissions in Terraform or Docker image management. For example:\n",
      "   - Ensure you're running commands in the correct directory that contains your Terraform configuration files.\n",
      "   - Manage permissions by verifying that the service account you’re using has the necessary rights to perform operations like creating storage buckets.\n",
      "\n",
      "6. **Ask Questions**: Don't hesitate to seek help in forums, study groups, or from your peers if you encounter difficulties.\n",
      "\n",
      "7. **Plan for Time Management**: Allocate your time wisely across the different topics within the module to ensure you cover all necessary areas before assessments.\n",
      "\n",
      "By reflecting on these strategies and engaging actively with the course material, you can enhance your performance in Module 1.\n",
      "\n",
      "### Follow-Up Question\n",
      "What specific topic within Docker and Terraform are you finding most challenging right now?\n",
      "\n",
      "function_call: ResponseFunctionToolCall(arguments='{\"query\":\"Terraform tips and common issues\"}', call_id='call_wOC1ZcojTwzlHqMF0kA4QdHh', name='search', type='function_call', id='fc_6874e76e4ad8819787c5f5a1d515e3aa0b0b1d4ba72eceb0', status='completed')\n",
      "\n",
      "Here are some tips and common issues you may encounter while working with Terraform:\n",
      "\n",
      "### Tips for Using Terraform\n",
      "\n",
      "1. **Initialization**: Always run `terraform init` before applying any configurations. This command sets up the initial state and downloads necessary providers.\n",
      "\n",
      "2. **Configuration Files**: Ensure your Terraform configuration files are correctly set up in the working directory. This avoids errors like \"Terraform initialized in an empty directory.\"\n",
      "\n",
      "3. **Understand State Management**: The state file is crucial. It keeps track of your infrastructure. Familiarize yourself with managing state locks to avoid problems when applying changes.\n",
      "\n",
      "4. **Keep Permissions in Mind**: Verify that your service account has the required permissions for the resources you're creating. For example, if you're encountering a permission error, you might need to declare the correct project ID in your Terraform configuration.\n",
      "\n",
      "5. **Network Issues**: If you face issues querying provider packages, check your internet connection and firewall or VPN settings. It might be blocking Terraform from accessing the necessary online resources.\n",
      "\n",
      "### Common Issues\n",
      "\n",
      "- **State Lock Issues**: If you encounter an error acquiring the state lock, it usually means another process is using it. Check for running Terraform commands that may be locking the state file.\n",
      "\n",
      "- **Invalid JWT Token on WSL**: If you receive an error about an invalid JWT token, this may be due to time synchronization issues on your machine. Running `sudo hwclock -s` can help resolve this.\n",
      "\n",
      "- **Provider Query Failures**: If the provider can't be queried, ensure your VPN is correctly configured if you're behind one. Sometimes clearing your browser cookies or restarting your network may help.\n",
      "\n",
      "By addressing these issues and adhering to best practices, you can improve your experience with Terraform.\n",
      "\n",
      "### Follow-Up Question\n",
      "Are you encountering any specific error messages or issues while using Terraform that I can help you troubleshoot?\n",
      "\n",
      "If you have any other questions in the future or need assistance, feel free to reach out. Have a great day!\n",
      "\n",
      "Understood! If you need anything else later, just let me know. Take care!\n",
      "\n",
      "It seems like you may want to end our conversation. If you need anything else in the future, feel free to reach out. Have a great day!\n",
      "\n",
      "If you have more questions or need assistance later, I'm here to help. Otherwise, take care!\n",
      "\n",
      "It sounds like you want to end this conversation. If you ever have questions or need assistance in the future, don't hesitate to reach out. Have a great day!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "while True: # main Q&A loop\n",
    "    question = input() # How do I do my best for module 1?\n",
    "    print(f\"Question: {question}\\n\")\n",
    "    if question == 'stop':\n",
    "        break\n",
    "\n",
    "    message = {\"role\": \"user\", \"content\": question}\n",
    "    chat_messages.append(message)\n",
    "\n",
    "    while True: # request-response loop - query API till get a message\n",
    "        response = client.responses.create(\n",
    "            model='gpt-4o-mini',\n",
    "            input=chat_messages,\n",
    "            tools=tools\n",
    "        )\n",
    "\n",
    "        has_messages = False\n",
    "        \n",
    "        for entry in response.output:\n",
    "            chat_messages.append(entry)\n",
    "        \n",
    "            if entry.type == 'function_call':      \n",
    "                print('function_call:', entry)\n",
    "                print()\n",
    "                result = do_call(entry)\n",
    "                chat_messages.append(result)\n",
    "            elif entry.type == 'message':\n",
    "                print(\"Response: \\n\")\n",
    "                print(entry.content[0].text)\n",
    "                print()\n",
    "                has_messages = True\n",
    "\n",
    "        if has_messages:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7609d8da",
   "metadata": {},
   "source": [
    "### chat_assistant.py\n",
    "\n",
    "\n",
    "* Tools - manages function tools for the agent\n",
    "    * add_tool(function, description): Register a function with its description\n",
    "    * get_tools(): Return list of registered tool descriptions\n",
    "    * function_call(tool_call_response): Execute a function call and return result\n",
    "\n",
    "* ChatInterface - handles user input and display formatting\n",
    "   * input(): Get user input\n",
    "   * display(message): Print a message\n",
    "   * display_function_call(entry, result): Show function calls in HTML format\n",
    "   * display_response(entry): Display AI responses with markdown\n",
    "\n",
    "\n",
    "* ChatAssistant - main orchestrator for chat conversations.\n",
    "    * __init__(tools, developer_prompt, chat_interface, client): Initialize assistant\n",
    "    * gpt(chat_messages): Make OpenAI API calls\n",
    "    * run(): Main chat loop handling user input and AI responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0a1bcbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chat_assistant \n",
    "\n",
    "# Tools \n",
    "tools = chat_assistant.Tools()\n",
    "tools.add_tool(search, search_tool)\n",
    "tools.get_tools()\n",
    "\n",
    "# Prompt Template\n",
    "developer_prompt = \"\"\"\n",
    "You're a course teaching assistant. \n",
    "You're given a question from a course student and your task is to answer it.\n",
    "\n",
    "Use FAQ if your own knowledge is not sufficient to answer the question.\n",
    "\n",
    "At the end of each response, ask the user a follow up question based on your answer.\n",
    "\"\"\".strip()\n",
    "\n",
    "chat_interface = chat_assistant.ChatInterface()\n",
    "\n",
    "\n",
    "chat = chat_assistant.ChatAssistant(\n",
    "    tools=tools,\n",
    "    developer_prompt=developer_prompt,\n",
    "    chat_interface=chat_interface,\n",
    "    client=client\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "25fad3a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <details>\n",
       "            <summary>Function call: <tt>search({\"query\":\"module 1 success tips\"})</tt></summary>\n",
       "            <div>\n",
       "                <b>Call</b>\n",
       "                <pre>ResponseFunctionToolCall(arguments='{\"query\":\"module 1 success tips\"}', call_id='call_m22hYTlP4sdRCFaLUzaW63Dh', name='search', type='function_call', id='fc_68756a59156081979471f6764dda43e6007886b35a6b5ae9', status='completed')</pre>\n",
       "            </div>\n",
       "            <div>\n",
       "                <b>Output</b>\n",
       "                <pre>[\n",
       "  {\n",
       "    \"text\": \"Even after installing pyspark correctly on linux machine (VM ) as per course instructions, faced a module not found error in jupyter notebook .\\nThe solution which worked for me(use following in jupyter notebook) :\\n!pip install findspark\\nimport findspark\\nfindspark.init()\\nThereafter , import pyspark and create spark contex<<t as usual\\nNone of the solutions above worked for me till I ran !pip3 install pyspark instead !pip install pyspark.\\nFilter based on conditions based on multiple columns\\nfrom pyspark.sql.functions import col\\nnew_final.filter((new_final.a_zone==\\\"Murray Hill\\\") & (new_final.b_zone==\\\"Midwood\\\")).show()\\nKrishna Anand\",\n",
       "    \"section\": \"Module 5: pyspark\",\n",
       "    \"question\": \"Module Not Found Error in Jupyter Notebook .\",\n",
       "    \"course\": \"data-engineering-zoomcamp\",\n",
       "    \"_id\": 322\n",
       "  },\n",
       "  {\n",
       "    \"text\": \"You need to look for the Py4J file and note the version of the filename. Once you know the version, you can update the export command accordingly, this is how you check yours:\\n` ls ${SPARK_HOME}/python/lib/ ` and then you add it in the export command, mine was:\\nexport PYTHONPATH=\\u201d${SPARK_HOME}/python/lib/Py4J-0.10.9.5-src.zip:${PYTHONPATH}\\u201d\\nMake sure that the version under `${SPARK_HOME}/python/lib/` matches the filename of py4j or you will encounter `ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`.\\nFor instance, if the file under `${SPARK_HOME}/python/lib/` was `py4j-0.10.9.3-src.zip`.\\nThen the export PYTHONPATH statement above should be changed to `export PYTHONPATH=\\\"${SPARK_HOME}/python/lib/py4j-0.10.9.3-src.zip:$PYTHONPATH\\\"` appropriately.\\nAdditionally, you can check for the version of \\u2018py4j\\u2019 of the spark you\\u2019re using from here and update as mentioned above.\\n~ Abhijit Chakraborty: Sometimes, even with adding the correct version of py4j might not solve the problem. Simply run pip install py4j and problem should be resolved.\",\n",
       "    \"section\": \"Module 5: pyspark\",\n",
       "    \"question\": \"Py4JJavaError - ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`\",\n",
       "    \"course\": \"data-engineering-zoomcamp\",\n",
       "    \"_id\": 323\n",
       "  },\n",
       "  {\n",
       "    \"text\": \"Following dbt with BigQuery on Docker readme.md, after `docker-compose build` and `docker-compose run dbt-bq-dtc init`, encountered error `ModuleNotFoundError: No module named 'pytz'`\\nSolution:\\nAdd `RUN python -m pip install --no-cache pytz` in the Dockerfile under `FROM --platform=$build_for python:3.9.9-slim-bullseye as base`\",\n",
       "    \"section\": \"Module 4: analytics engineering with dbt\",\n",
       "    \"question\": \"DBT - Error: No module named 'pytz' while setting up dbt with docker\",\n",
       "    \"course\": \"data-engineering-zoomcamp\",\n",
       "    \"_id\": 299\n",
       "  },\n",
       "  {\n",
       "    \"text\": \"Issue:\\ne\\u2026\\nSolution:\\npip install psycopg2-binary\\nIf you already have it, you might need to update it:\\npip install psycopg2-binary --upgrade\\nOther methods, if the above fails:\\nif you are getting the \\u201c ModuleNotFoundError: No module named 'psycopg2' \\u201c error even after the above installation, then try updating conda using the command conda update -n base -c defaults conda. Or if you are using pip, then try updating it before installing the psycopg packages i.e\\nFirst uninstall the psycopg package\\nThen update conda or pip\\nThen install psycopg again using pip.\\nif you are still facing error with r pcycopg2 and showing pg_config not found then you will have to install postgresql. in MAC it is brew install postgresql\",\n",
       "    \"section\": \"Module 1: Docker and Terraform\",\n",
       "    \"question\": \"Postgres - ModuleNotFoundError: No module named 'psycopg2'\",\n",
       "    \"course\": \"data-engineering-zoomcamp\",\n",
       "    \"_id\": 112\n",
       "  },\n",
       "  {\n",
       "    \"text\": \"create_engine('postgresql://root:root@localhost:5432/ny_taxi')  I get the error \\\"TypeError: 'module' object is not callable\\\"\\nSolution:\\nconn_string = \\\"postgresql+psycopg://root:root@localhost:5432/ny_taxi\\\"\\nengine = create_engine(conn_string)\",\n",
       "    \"section\": \"Module 1: Docker and Terraform\",\n",
       "    \"question\": \"Python - SQLALchemy - TypeError 'module' object is not callable\",\n",
       "    \"course\": \"data-engineering-zoomcamp\",\n",
       "    \"_id\": 124\n",
       "  }\n",
       "]</pre>\n",
       "            </div>\n",
       "            \n",
       "            </details>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <div><b>Assistant:</b></div>\n",
       "                <div><p>To do well in Module 1, focus on the following key strategies:</p>\n",
       "<ol>\n",
       "<li>\n",
       "<p><strong>Understand the Basics</strong>: Make sure you grasp foundational concepts related to PostgreSQL and Docker. Review documentation and tutorials if needed.</p>\n",
       "</li>\n",
       "<li>\n",
       "<p><strong>Hands-On Practice</strong>: Set up your environment as instructed, and practice writing SQL queries. Establish connections using SQLAlchemy, ensuring you resolve any import issues, such as the 'ModuleNotFoundError'.</p>\n",
       "</li>\n",
       "<li>\n",
       "<p><strong>Test Your Knowledge</strong>: Regularly complete exercises and quizzes within the module. They help consolidate your learning.</p>\n",
       "</li>\n",
       "<li>\n",
       "<p><strong>Engage with the Community</strong>: Participate in discussions or study groups. Share challenges and solutions to benefit from peer support.</p>\n",
       "</li>\n",
       "<li>\n",
       "<p><strong>Seek Help When Stuck</strong>: Don’t hesitate to ask questions if you encounter difficulties. Resources are available for troubleshooting issues, such as installation errors.</p>\n",
       "</li>\n",
       "<li>\n",
       "<p><strong>Review and Reflect</strong>: After completing the module, review the key topics covered to reinforce your understanding.</p>\n",
       "</li>\n",
       "</ol>\n",
       "<p>Is there a particular area in Module 1 where you're feeling stuck?</p></div>\n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <div><b>Assistant:</b></div>\n",
       "                <div><p>If you have any further questions or need assistance in the future, feel free to reach out. Have a great day!</p></div>\n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <div><b>Assistant:</b></div>\n",
       "                <div><p>If you’d like to stop interacting, that’s perfectly fine! Take care! If you ever have questions in the future, feel free to return.</p></div>\n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat ended.\n"
     ]
    }
   ],
   "source": [
    "chat.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f55f84",
   "metadata": {},
   "source": [
    "### Multiple Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7074f46",
   "metadata": {},
   "source": [
    "#### New tool: `add_entry` -> adds new document in the FAQ database.\n",
    "\n",
    "What if we also want to use this chat app to add new entires to the FAQ? we'll need another function for it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "75105993",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_entry(question, answer):\n",
    "    doc = {\n",
    "        'question': question,\n",
    "        'text': answer,\n",
    "        'section': 'user added',\n",
    "        'course': 'data-engineering-zoomcamp'\n",
    "    }\n",
    "    index.append(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d144b2c7",
   "metadata": {},
   "source": [
    "Description about the tool:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "89ded5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_entry_description = {\n",
    "    \"type\": \"function\",\n",
    "    \"name\": \"add_entry\",\n",
    "    \"description\": \"Add an entry to the FAQ database\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"question\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The question to be added to the FAQ database\",\n",
    "            },\n",
    "            \"answer\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The answer to the question\",\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"question\", \"answer\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a872a30c",
   "metadata": {},
   "source": [
    "Now let's add the new tool:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "828a911c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'function',\n",
       "  'name': 'search',\n",
       "  'description': 'Search the FAQ database',\n",
       "  'parameters': {'type': 'object',\n",
       "   'properties': {'query': {'type': 'string',\n",
       "     'description': 'Search query text to look up in the course FAQ.'}},\n",
       "   'required': ['query'],\n",
       "   'additionalProperties': False}},\n",
       " {'type': 'function',\n",
       "  'name': 'add_entry',\n",
       "  'description': 'Add an entry to the FAQ database',\n",
       "  'parameters': {'type': 'object',\n",
       "   'properties': {'question': {'type': 'string',\n",
       "     'description': 'The question to be added to the FAQ database'},\n",
       "    'answer': {'type': 'string', 'description': 'The answer to the question'}},\n",
       "   'required': ['question', 'answer'],\n",
       "   'additionalProperties': False}}]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools.add_tool(add_entry, add_entry_description)\n",
    "\n",
    "tools.get_tools()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "864a3c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt Template\n",
    "developer_prompt = \"\"\"\n",
    "You're a course teaching assistant. \n",
    "You're given a question from a course student and your task is to answer it.\n",
    "\n",
    "Use FAQ if your own knowledge is not sufficient to answer the question.\n",
    "\n",
    "At the end of each response, ask the user a follow up question based on your answer.\n",
    "\"\"\".strip()\n",
    "\n",
    "chat_interface = chat_assistant.ChatInterface()\n",
    "\n",
    "\n",
    "chat = chat_assistant.ChatAssistant(\n",
    "    tools=tools,\n",
    "    developer_prompt=developer_prompt,\n",
    "    chat_interface=chat_interface,\n",
    "    client=client\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d363b1a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <details>\n",
       "            <summary>Function call: <tt>search({\"query\":\"how to do well in module 1\"})</tt></summary>\n",
       "            <div>\n",
       "                <b>Call</b>\n",
       "                <pre>ResponseFunctionToolCall(arguments='{\"query\":\"how to do well in module 1\"}', call_id='call_yLYnOSUtMsfetg5w1bDMyJPg', name='search', type='function_call', id='fc_68756c9688bc819394394ed866d43f8a0be242bb1dd63c6d', status='completed')</pre>\n",
       "            </div>\n",
       "            <div>\n",
       "                <b>Output</b>\n",
       "                <pre>[\n",
       "  {\n",
       "    \"text\": \"Even after installing pyspark correctly on linux machine (VM ) as per course instructions, faced a module not found error in jupyter notebook .\\nThe solution which worked for me(use following in jupyter notebook) :\\n!pip install findspark\\nimport findspark\\nfindspark.init()\\nThereafter , import pyspark and create spark contex<<t as usual\\nNone of the solutions above worked for me till I ran !pip3 install pyspark instead !pip install pyspark.\\nFilter based on conditions based on multiple columns\\nfrom pyspark.sql.functions import col\\nnew_final.filter((new_final.a_zone==\\\"Murray Hill\\\") & (new_final.b_zone==\\\"Midwood\\\")).show()\\nKrishna Anand\",\n",
       "    \"section\": \"Module 5: pyspark\",\n",
       "    \"question\": \"Module Not Found Error in Jupyter Notebook .\",\n",
       "    \"course\": \"data-engineering-zoomcamp\",\n",
       "    \"_id\": 322\n",
       "  },\n",
       "  {\n",
       "    \"text\": \"You need to look for the Py4J file and note the version of the filename. Once you know the version, you can update the export command accordingly, this is how you check yours:\\n` ls ${SPARK_HOME}/python/lib/ ` and then you add it in the export command, mine was:\\nexport PYTHONPATH=\\u201d${SPARK_HOME}/python/lib/Py4J-0.10.9.5-src.zip:${PYTHONPATH}\\u201d\\nMake sure that the version under `${SPARK_HOME}/python/lib/` matches the filename of py4j or you will encounter `ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`.\\nFor instance, if the file under `${SPARK_HOME}/python/lib/` was `py4j-0.10.9.3-src.zip`.\\nThen the export PYTHONPATH statement above should be changed to `export PYTHONPATH=\\\"${SPARK_HOME}/python/lib/py4j-0.10.9.3-src.zip:$PYTHONPATH\\\"` appropriately.\\nAdditionally, you can check for the version of \\u2018py4j\\u2019 of the spark you\\u2019re using from here and update as mentioned above.\\n~ Abhijit Chakraborty: Sometimes, even with adding the correct version of py4j might not solve the problem. Simply run pip install py4j and problem should be resolved.\",\n",
       "    \"section\": \"Module 5: pyspark\",\n",
       "    \"question\": \"Py4JJavaError - ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`\",\n",
       "    \"course\": \"data-engineering-zoomcamp\",\n",
       "    \"_id\": 323\n",
       "  },\n",
       "  {\n",
       "    \"text\": \"Following dbt with BigQuery on Docker readme.md, after `docker-compose build` and `docker-compose run dbt-bq-dtc init`, encountered error `ModuleNotFoundError: No module named 'pytz'`\\nSolution:\\nAdd `RUN python -m pip install --no-cache pytz` in the Dockerfile under `FROM --platform=$build_for python:3.9.9-slim-bullseye as base`\",\n",
       "    \"section\": \"Module 4: analytics engineering with dbt\",\n",
       "    \"question\": \"DBT - Error: No module named 'pytz' while setting up dbt with docker\",\n",
       "    \"course\": \"data-engineering-zoomcamp\",\n",
       "    \"_id\": 299\n",
       "  },\n",
       "  {\n",
       "    \"text\": \"create_engine('postgresql://root:root@localhost:5432/ny_taxi')  I get the error \\\"TypeError: 'module' object is not callable\\\"\\nSolution:\\nconn_string = \\\"postgresql+psycopg://root:root@localhost:5432/ny_taxi\\\"\\nengine = create_engine(conn_string)\",\n",
       "    \"section\": \"Module 1: Docker and Terraform\",\n",
       "    \"question\": \"Python - SQLALchemy - TypeError 'module' object is not callable\",\n",
       "    \"course\": \"data-engineering-zoomcamp\",\n",
       "    \"_id\": 124\n",
       "  },\n",
       "  {\n",
       "    \"text\": \"Error raised during the jupyter notebook\\u2019s cell execution:\\nengine = create_engine('postgresql://root:root@localhost:5432/ny_taxi').\\nSolution: Need to install Python module \\u201cpsycopg2\\u201d. Can be installed by Conda or pip.\",\n",
       "    \"section\": \"Module 1: Docker and Terraform\",\n",
       "    \"question\": \"Python - SQLAlchemy - ModuleNotFoundError: No module named 'psycopg2'.\",\n",
       "    \"course\": \"data-engineering-zoomcamp\",\n",
       "    \"_id\": 125\n",
       "  }\n",
       "]</pre>\n",
       "            </div>\n",
       "            \n",
       "            </details>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <div><b>Assistant:</b></div>\n",
       "                <div><p>To do well in Module 1, which covers Docker and Terraform, here are some essential tips:</p>\n",
       "<ol>\n",
       "<li>\n",
       "<p><strong>Understand the Basics</strong>: Make sure you have a good grasp of Docker and Terraform fundamentals. Review the introductory materials provided in the module.</p>\n",
       "</li>\n",
       "<li>\n",
       "<p><strong>Hands-On Practice</strong>: Engage in the hands-on exercises. Set up your Docker containers and practice deploying configurations with Terraform. Experimenting will deepen your understanding.</p>\n",
       "</li>\n",
       "<li>\n",
       "<p><strong>Resolve Common Issues</strong>: If you run into errors—such as <code>ModuleNotFoundError</code> for required packages (like <code>psycopg2</code> or similar)—follow the recommended solutions. For instance, you might need to install certain Python modules that are essential for execution.</p>\n",
       "</li>\n",
       "<li>\n",
       "<p><strong>Connect with Peers</strong>: Discuss concepts and share problems with classmates on forums or group chats. Collaborative learning can provide different perspectives and solutions.</p>\n",
       "</li>\n",
       "<li>\n",
       "<p><strong>Utilize Resources</strong>: Use any additional resources, such as documentation, tutorials, or the FAQ section for this course, to support your learning.</p>\n",
       "</li>\n",
       "<li>\n",
       "<p><strong>Prepare for Assessments</strong>: Regularly review the material and ensure you are prepared for any assessments tied to the module. Practice coding problems if applicable.</p>\n",
       "</li>\n",
       "</ol>\n",
       "<p>Would you like guidance on a specific topic within Module 1 or any particular challenges you are facing?</p></div>\n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <details>\n",
       "            <summary>Function call: <tt>add_entry({\"question\":\"How can I do well in Module 1?\",\"a...)</tt></summary>\n",
       "            <div>\n",
       "                <b>Call</b>\n",
       "                <pre>ResponseFunctionToolCall(arguments='{\"question\":\"How can I do well in Module 1?\",\"answer\":\"1. **Understand the Basics**: Make sure you have a good grasp of Docker and Terraform fundamentals. Review the introductory materials provided in the module.\\\\n\\\\n2. **Hands-On Practice**: Engage in the hands-on exercises. Set up your Docker containers and practice deploying configurations with Terraform. Experimenting will deepen your understanding.\\\\n\\\\n3. **Resolve Common Issues**: If you run into errors—such as `ModuleNotFoundError` for required packages (like `psycopg2` or similar)—follow the recommended solutions. For instance, you might need to install certain Python modules that are essential for execution.\\\\n\\\\n4. **Connect with Peers**: Discuss concepts and share problems with classmates on forums or group chats. Collaborative learning can provide different perspectives and solutions.\\\\n\\\\n5. **Utilize Resources**: Use any additional resources, such as documentation, tutorials, or the FAQ section for this course, to support your learning.\\\\n\\\\n6. **Prepare for Assessments**: Regularly review the material and ensure you are prepared for any assessments tied to the module. Practice coding problems if applicable.\"}', call_id='call_glkaAUr27DMH1tyErKuApM4O', name='add_entry', type='function_call', id='fc_68756cb944f08193b2d2272523fbd7840be242bb1dd63c6d', status='completed')</pre>\n",
       "            </div>\n",
       "            <div>\n",
       "                <b>Output</b>\n",
       "                <pre>null</pre>\n",
       "            </div>\n",
       "            \n",
       "            </details>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <div><b>Assistant:</b></div>\n",
       "                <div><p>I've added the tips for doing well in Module 1 to the FAQ database. </p>\n",
       "<p>If you have any other questions or need further assistance with your studies, feel free to ask!</p></div>\n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat ended.\n"
     ]
    }
   ],
   "source": [
    "chat.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a931f4dc",
   "metadata": {},
   "source": [
    "We actually asked chatbot to add question: `How can I do well in Module 1?` and answer to FAQ database.\n",
    "\n",
    "And check that it's in the index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "aa3522a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'How can I do well in Module 1?',\n",
       " 'text': '1. **Understand the Basics**: Make sure you have a good grasp of Docker and Terraform fundamentals. Review the introductory materials provided in the module.\\n\\n2. **Hands-On Practice**: Engage in the hands-on exercises. Set up your Docker containers and practice deploying configurations with Terraform. Experimenting will deepen your understanding.\\n\\n3. **Resolve Common Issues**: If you run into errors—such as `ModuleNotFoundError` for required packages (like `psycopg2` or similar)—follow the recommended solutions. For instance, you might need to install certain Python modules that are essential for execution.\\n\\n4. **Connect with Peers**: Discuss concepts and share problems with classmates on forums or group chats. Collaborative learning can provide different perspectives and solutions.\\n\\n5. **Utilize Resources**: Use any additional resources, such as documentation, tutorials, or the FAQ section for this course, to support your learning.\\n\\n6. **Prepare for Assessments**: Regularly review the material and ensure you are prepared for any assessments tied to the module. Practice coding problems if applicable.',\n",
       " 'section': 'user added',\n",
       " 'course': 'data-engineering-zoomcamp'}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.docs[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b99e06",
   "metadata": {},
   "source": [
    "### Part-4: PydanticAI \n",
    "\n",
    "There are frameworks that makes it easier for us to create `Agents`:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511d85a5",
   "metadata": {},
   "source": [
    "Tools "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86b124db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query):\n",
    "    boost = {'question': 3.0, 'section': 0.5}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={'course': 'data-engineering-zoomcamp'},\n",
    "        boost_dict=boost,\n",
    "        num_results = 5,\n",
    "        output_ids=True\n",
    "    )\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def add_entry(question, answer):\n",
    "    doc = {\n",
    "        'question': question,\n",
    "        'text': answer,\n",
    "        'section': 'user added',\n",
    "        'course': 'data-engineering-zoomcamp'\n",
    "    }\n",
    "    index.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23d8c3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# installing pydanticAI \n",
    "# !pip install pydantic-ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4474580e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic_ai import Agent, RunContext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67bd1bc5",
   "metadata": {},
   "source": [
    "Create an Agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d9f1d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'openai:gpt-4o-mini'\n",
    "\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "You're a course teaching assistant. \n",
    "You're given a question from a course student and your task is to answer it.\n",
    "\n",
    "Use FAQ if your own knowledge is not sufficient to answer the question.\n",
    "\n",
    "At the end of each response, ask the user a follow up question based on your answer.\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "faf9be87",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_agent = Agent(  \n",
    "    model_name,\n",
    "    system_prompt=system_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb80e3b8",
   "metadata": {},
   "source": [
    "Now we can use it to automate tool description:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53e495da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List \n",
    "\n",
    "@chat_agent.tool\n",
    "def search_tool(ctx: RunContext, query: str) -> List[Dict[str, str]]: \n",
    "    \"\"\"\n",
    "    Search the FAQ for relevant entries matching the query. \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    query : str\n",
    "        The search query string provided by the user. \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        A list of search results (up to 5), each containing relevance information \n",
    "        and associated output IDs.   \n",
    "    \"\"\"\n",
    "    print(f\"search('{query})\")\n",
    "    return search(query)\n",
    "\n",
    "\n",
    "@chat_agent.tool\n",
    "def add_entry_tool(ctx: RunContext, question: str, answer: str) -> None: \n",
    "    \"\"\"\n",
    "    Add a new question-answer entry to FAQ index.\n",
    "\n",
    "    This function creates a document with given question and answer, \n",
    "    tagging it as user-added content. \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    question: str \n",
    "        The question text to be added to the index. \n",
    "\n",
    "    answer: str \n",
    "        The answer or explaination corresponding to the question.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    return add_entry(question, answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c971bf6a",
   "metadata": {},
   "source": [
    "It reads the function's docstring to automatically create function description, so we don't need to worry about it. \n",
    "\n",
    "Let's use it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3fe6769a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search('Can I join the course now?)\n",
      "Yes, you can still join the course even if it has already started. You are eligible to submit homework assignments without registering, although there will be deadlines for final project submissions. Just make sure not to leave everything until the last minute!\n",
      "\n",
      "Would you like to know more about the course materials or any deadlines?\n"
     ]
    }
   ],
   "source": [
    "question = \"I just discovered the course, Can I join now?\"\n",
    "\n",
    "agent_run = await chat_agent.run(question)\n",
    "\n",
    "print(agent_run.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577b8cea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
